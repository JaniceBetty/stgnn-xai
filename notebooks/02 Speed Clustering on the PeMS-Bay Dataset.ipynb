{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EJvwmuUtNSE7"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Set the main path in the root folder of the project.\n",
        "sys.path.append(os.path.join('..'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mGwHPWyZNSE-"
      },
      "outputs": [],
      "source": [
        "# Settings for autoreloading.\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8WA-blstNSE_"
      },
      "outputs": [],
      "source": [
        "from src.utils.seed import set_random_seed\n",
        "\n",
        "# Set the random seed for deterministic operations.\n",
        "SEED = 42\n",
        "set_random_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N95f6shPNSE_",
        "outputId": "d84bda92-e796-4ff1-946d-7d8c1d0a83c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The selected device is: \"cuda\"\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Set the device for training and querying the model.\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'The selected device is: \"{DEVICE}\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDozaYp5NSFA"
      },
      "source": [
        "# Loading the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "oi_X5-kpNSFB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "BASE_DATA_DIR = os.path.join('..', 'data', 'pems-bay')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1zZ4_-yMNSFC"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open(os.path.join(BASE_DATA_DIR, 'processed', 'scaler.pkl'), 'rb') as f:\n",
        "    scaler = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Q7_8Ro4QNSFC"
      },
      "outputs": [],
      "source": [
        "from src.spatial_temporal_gnn.model import SpatialTemporalGNN\n",
        "from src.data.data_extraction import get_adjacency_matrix\n",
        "\n",
        "# Get the adjacency matrix\n",
        "adj_matrix_structure = get_adjacency_matrix(\n",
        "    os.path.join(BASE_DATA_DIR, 'raw', 'adj_mx_pems_bay.pkl'))\n",
        "\n",
        "# Get the header of the adjacency matrix, the node indices and the\n",
        "# matrix itself.\n",
        "header, node_ids_dict, adj_matrix = adj_matrix_structure\n",
        "\n",
        "# Get the STGNN and load the checkpoints.\n",
        "spatial_temporal_gnn = SpatialTemporalGNN(9, 1, 12, 12, adj_matrix, DEVICE, 64)\n",
        "\n",
        "stgnn_checkpoints_path = os.path.join('..', 'models', 'checkpoints',\n",
        "                                      'st_gnn_pems_bay.pth')\n",
        "\n",
        "stgnn_checkpoints = torch.load(stgnn_checkpoints_path)\n",
        "spatial_temporal_gnn.load_state_dict(stgnn_checkpoints['model_state_dict'])\n",
        "\n",
        "# Set the model in evaluation mode.\n",
        "spatial_temporal_gnn.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TzeGJl4DNSFD"
      },
      "outputs": [],
      "source": [
        "from src.data.data_extraction import get_locations_dataframe\n",
        "\n",
        "# Get the dataframe containing the latitude and longitude of each sensor.\n",
        "locations_df = get_locations_dataframe(\n",
        "    os.path.join(BASE_DATA_DIR, 'raw', 'graph_sensor_locations_pems_bay.csv'),\n",
        "    has_header=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jqCGwKzNNSFE"
      },
      "outputs": [],
      "source": [
        "# Get the node positions dictionary.\n",
        "node_pos_dict = { i: id for id, i in node_ids_dict.items() }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "L31nXfubNSFE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from src.spatial_temporal_gnn.prediction import predict\n",
        "\n",
        "# Get the data and the values predicted by the STGNN.\n",
        "x_train = np.load(os.path.join(BASE_DATA_DIR, 'predicted', 'x_train.npy'))\n",
        "y_train = np.load(os.path.join(BASE_DATA_DIR, 'predicted', 'y_train.npy'))\n",
        "x_val = np.load(os.path.join(BASE_DATA_DIR, 'predicted', 'x_val.npy'))\n",
        "y_val = np.load(os.path.join(BASE_DATA_DIR, 'predicted', 'y_val.npy'))\n",
        "x_test = np.load(os.path.join(BASE_DATA_DIR, 'predicted', 'x_test.npy'))\n",
        "y_test = np.load(os.path.join(BASE_DATA_DIR, 'predicted', 'y_test.npy'))\n",
        "\n",
        "# Get the time information of the train, validation and test sets.\n",
        "x_train_time = np.load(\n",
        "    os.path.join(BASE_DATA_DIR, 'processed', 'x_train_time.npy'))\n",
        "y_train_time = np.load(\n",
        "    os.path.join(BASE_DATA_DIR, 'processed', 'y_train_time.npy'))\n",
        "x_val_time = np.load(\n",
        "    os.path.join(BASE_DATA_DIR, 'processed', 'x_val_time.npy'))\n",
        "y_val_time = np.load(\n",
        "    os.path.join(BASE_DATA_DIR, 'processed', 'y_val_time.npy'))\n",
        "x_test_time = np.load(\n",
        "    os.path.join(BASE_DATA_DIR, 'processed', 'x_test_time.npy'))\n",
        "y_test_time = np.load(\n",
        "    os.path.join(BASE_DATA_DIR, 'processed', 'y_test_time.npy'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RfBcpAe-NSFF"
      },
      "outputs": [],
      "source": [
        "# Turn the results in kilometers per hour.\n",
        "MPH_TO_KMH_FACTOR = 1.609344\n",
        "\n",
        "y_train = y_train * MPH_TO_KMH_FACTOR\n",
        "y_val = y_val * MPH_TO_KMH_FACTOR\n",
        "y_test = y_test * MPH_TO_KMH_FACTOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-CpxEtLONSFF"
      },
      "outputs": [],
      "source": [
        "_, n_timesteps, n_nodes, _ = y_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_bSXgnINSFF"
      },
      "source": [
        "# Adjacency Distance Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Im5Nr1qgNSFF"
      },
      "outputs": [],
      "source": [
        "from src.explanation.clustering.clustering import (\n",
        "    get_adjacency_distance_matrix)\n",
        "\n",
        "adj_distance_matrix = get_adjacency_distance_matrix(adj_matrix, n_timesteps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3C4QgL1SNSFG",
        "outputId": "059ff6be-c007-49e0-cc3a-018ade3c5ac0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of the Adjacency Distance Matrix: (3900, 3900)\n"
          ]
        }
      ],
      "source": [
        "print(f'Shape of the Adjacency Distance Matrix: {adj_distance_matrix.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFQO173FNSFG"
      },
      "source": [
        "# Temporal Distance Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "evlNrnXZNSFG"
      },
      "outputs": [],
      "source": [
        "from src.explanation.clustering.clustering import (\n",
        "    get_temporal_distance_matrix)\n",
        "\n",
        "temporal_distance_matrix = get_temporal_distance_matrix(n_nodes, n_timesteps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENHh4g0XNSFG",
        "outputId": "a0cab76c-fb0a-4397-931d-ece209d29396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of the Temporal Distance Matrix: (3900, 3900)\n"
          ]
        }
      ],
      "source": [
        "print('Shape of the Temporal Distance Matrix:',\n",
        "      f'{temporal_distance_matrix.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HoLFLbwNSFG"
      },
      "source": [
        "# Clustering Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISnmYYA1NSFH",
        "outputId": "5b6dd104-69c6-4ed3-9743-67225cf95844"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eps: 0.1 min_samples: 5\n",
            "\tWithin-Cluster Variance: 0.982 Connected Cluster Dissimilarity: 4.29 Noise points ratio: 0.947\n",
            "\n",
            "eps: 0.1 min_samples: 7\n",
            "\tWithin-Cluster Variance: 0.997 Connected Cluster Dissimilarity: 4.5 Noise points ratio: 0.99\n",
            "\n",
            "eps: 0.1 min_samples: 10\n",
            "\tWithin-Cluster Variance: 1 Connected Cluster Dissimilarity: 0.979 Noise points ratio: 0.999\n",
            "\n",
            "eps: 0.1 min_samples: 12\n",
            "\tWithin-Cluster Variance: 1 Connected Cluster Dissimilarity: 0.0745 Noise points ratio: 1\n",
            "\n",
            "eps: 0.1 min_samples: 15\n",
            "\tWithin-Cluster Variance: 1 Connected Cluster Dissimilarity: 0 Noise points ratio: 1\n",
            "\n",
            "eps: 0.1 min_samples: 17\n",
            "\tWithin-Cluster Variance: 1 Connected Cluster Dissimilarity: 0 Noise points ratio: 1\n",
            "\n",
            "eps: 0.1 min_samples: 20\n",
            "\tWithin-Cluster Variance: 1 Connected Cluster Dissimilarity: 0 Noise points ratio: 1\n",
            "\n",
            "eps: 0.15 min_samples: 5\n",
            "\tWithin-Cluster Variance: 0.838 Connected Cluster Dissimilarity: 6.13 Noise points ratio: 0.676\n",
            "\n",
            "eps: 0.15 min_samples: 7\n",
            "\tWithin-Cluster Variance: 0.962 Connected Cluster Dissimilarity: 4.56 Noise points ratio: 0.888\n",
            "\n",
            "eps: 0.15 min_samples: 10\n",
            "\tWithin-Cluster Variance: 0.995 Connected Cluster Dissimilarity: 3.96 Noise points ratio: 0.982\n",
            "\n",
            "eps: 0.15 min_samples: 12\n",
            "\tWithin-Cluster Variance: 0.998 Connected Cluster Dissimilarity: 2.36 Noise points ratio: 0.995\n",
            "\n",
            "eps: 0.15 min_samples: 15\n",
            "\tWithin-Cluster Variance: 1 Connected Cluster Dissimilarity: 0.107 Noise points ratio: 0.999\n",
            "\n",
            "eps: 0.15 min_samples: 17\n",
            "\tWithin-Cluster Variance: 1 Connected Cluster Dissimilarity: 0.00553 Noise points ratio: 1\n",
            "\n",
            "eps: 0.15 min_samples: 20\n",
            "\tWithin-Cluster Variance: 1 Connected Cluster Dissimilarity: 0 Noise points ratio: 1\n",
            "\n",
            "eps: 0.2 min_samples: 5\n",
            "\tWithin-Cluster Variance: 0.409 Connected Cluster Dissimilarity: 7.45 Noise points ratio: 0.202\n",
            "\n",
            "eps: 0.2 min_samples: 7\n",
            "\tWithin-Cluster Variance: 0.782 Connected Cluster Dissimilarity: 6.1 Noise points ratio: 0.568\n",
            "\n",
            "eps: 0.2 min_samples: 10\n",
            "\tWithin-Cluster Variance: 0.945 Connected Cluster Dissimilarity: 4.58 Noise points ratio: 0.842\n",
            "\n",
            "eps: 0.2 min_samples: 12\n",
            "\tWithin-Cluster Variance: 0.982 Connected Cluster Dissimilarity: 4.15 Noise points ratio: 0.932\n",
            "\n",
            "eps: 0.2 min_samples: 15\n",
            "\tWithin-Cluster Variance: 0.994 Connected Cluster Dissimilarity: 4.32 Noise points ratio: 0.977\n",
            "\n",
            "eps: 0.2 min_samples: 17\n",
            "\tWithin-Cluster Variance: 0.998 Connected Cluster Dissimilarity: 2.51 Noise points ratio: 0.99\n",
            "\n",
            "eps: 0.2 min_samples: 20\n",
            "\tWithin-Cluster Variance: 1 Connected Cluster Dissimilarity: 0.598 Noise points ratio: 0.997\n",
            "\n",
            "eps: 0.25 min_samples: 5\n",
            "\tWithin-Cluster Variance: 0.113 Connected Cluster Dissimilarity: 8.84 Noise points ratio: 0.0313\n",
            "\n",
            "eps: 0.25 min_samples: 7\n",
            "\tWithin-Cluster Variance: 0.649 Connected Cluster Dissimilarity: 6.96 Noise points ratio: 0.391\n",
            "\n",
            "eps: 0.25 min_samples: 10\n",
            "\tWithin-Cluster Variance: 0.811 Connected Cluster Dissimilarity: 5.8 Noise points ratio: 0.602\n",
            "\n",
            "eps: 0.25 min_samples: 12\n",
            "\tWithin-Cluster Variance: 0.917 Connected Cluster Dissimilarity: 4.9 Noise points ratio: 0.771\n",
            "\n",
            "eps: 0.25 min_samples: 15\n",
            "\tWithin-Cluster Variance: 0.973 Connected Cluster Dissimilarity: 4.31 Noise points ratio: 0.904\n",
            "\n",
            "eps: 0.25 min_samples: 17\n",
            "\tWithin-Cluster Variance: 0.987 Connected Cluster Dissimilarity: 4.11 Noise points ratio: 0.949\n",
            "\n",
            "eps: 0.25 min_samples: 20\n",
            "\tWithin-Cluster Variance: 0.995 Connected Cluster Dissimilarity: 3.53 Noise points ratio: 0.98\n",
            "\n",
            "eps: 0.3 min_samples: 5\n",
            "\tWithin-Cluster Variance: 0.107 Connected Cluster Dissimilarity: 9.06 Noise points ratio: 0.0107\n",
            "\n",
            "eps: 0.3 min_samples: 7\n",
            "\tWithin-Cluster Variance: 0.301 Connected Cluster Dissimilarity: 7.97 Noise points ratio: 0.0996\n",
            "\n",
            "eps: 0.3 min_samples: 10\n",
            "\tWithin-Cluster Variance: 0.654 Connected Cluster Dissimilarity: 6.69 Noise points ratio: 0.372\n",
            "\n",
            "eps: 0.3 min_samples: 12\n",
            "\tWithin-Cluster Variance: 0.76 Connected Cluster Dissimilarity: 5.91 Noise points ratio: 0.501\n",
            "\n",
            "eps: 0.3 min_samples: 15\n",
            "\tWithin-Cluster Variance: 0.888 Connected Cluster Dissimilarity: 4.95 Noise points ratio: 0.697\n",
            "\n",
            "eps: 0.3 min_samples: 17\n",
            "\tWithin-Cluster Variance: 0.932 Connected Cluster Dissimilarity: 4.55 Noise points ratio: 0.795\n",
            "\n",
            "eps: 0.3 min_samples: 20\n",
            "\tWithin-Cluster Variance: 0.973 Connected Cluster Dissimilarity: 4.16 Noise points ratio: 0.897\n",
            "\n",
            "eps: 0.35 min_samples: 5\n",
            "\tWithin-Cluster Variance: 0.138 Connected Cluster Dissimilarity: 9.09 Noise points ratio: 0.00485\n",
            "\n",
            "eps: 0.35 min_samples: 7\n",
            "\tWithin-Cluster Variance: 0.17 Connected Cluster Dissimilarity: 8.63 Noise points ratio: 0.0261\n",
            "\n",
            "eps: 0.35 min_samples: 10\n",
            "\tWithin-Cluster Variance: 0.572 Connected Cluster Dissimilarity: 7.13 Noise points ratio: 0.26\n",
            "\n",
            "eps: 0.35 min_samples: 12\n",
            "\tWithin-Cluster Variance: 0.655 Connected Cluster Dissimilarity: 6.67 Noise points ratio: 0.354\n",
            "\n",
            "eps: 0.35 min_samples: 15\n",
            "\tWithin-Cluster Variance: 0.799 Connected Cluster Dissimilarity: 5.7 Noise points ratio: 0.535\n",
            "\n",
            "eps: 0.35 min_samples: 17\n",
            "\tWithin-Cluster Variance: 0.853 Connected Cluster Dissimilarity: 5.26 Noise points ratio: 0.623\n",
            "\n",
            "eps: 0.35 min_samples: 20\n",
            "\tWithin-Cluster Variance: 0.922 Connected Cluster Dissimilarity: 4.55 Noise points ratio: 0.756\n",
            "\n",
            "eps: 0.4 min_samples: 5\n",
            "\tWithin-Cluster Variance: 0.176 Connected Cluster Dissimilarity: 9.02 Noise points ratio: 0.00242\n",
            "\n",
            "eps: 0.4 min_samples: 7\n",
            "\tWithin-Cluster Variance: 0.18 Connected Cluster Dissimilarity: 8.86 Noise points ratio: 0.0113\n",
            "\n",
            "eps: 0.4 min_samples: 10\n",
            "\tWithin-Cluster Variance: 0.519 Connected Cluster Dissimilarity: 7.38 Noise points ratio: 0.169\n",
            "\n",
            "eps: 0.4 min_samples: 12\n",
            "\tWithin-Cluster Variance: 0.565 Connected Cluster Dissimilarity: 7.05 Noise points ratio: 0.221\n",
            "\n",
            "eps: 0.4 min_samples: 15\n",
            "\tWithin-Cluster Variance: 0.665 Connected Cluster Dissimilarity: 6.45 Noise points ratio: 0.336\n",
            "\n",
            "eps: 0.4 min_samples: 17\n",
            "\tWithin-Cluster Variance: 0.739 Connected Cluster Dissimilarity: 5.97 Noise points ratio: 0.428\n",
            "\n",
            "eps: 0.4 min_samples: 20\n",
            "\tWithin-Cluster Variance: 0.827 Connected Cluster Dissimilarity: 5.36 Noise points ratio: 0.56\n",
            "\n",
            "eps: 0.45 min_samples: 5\n",
            "\tWithin-Cluster Variance: 0.221 Connected Cluster Dissimilarity: 8.86 Noise points ratio: 0.00129\n",
            "\n",
            "eps: 0.45 min_samples: 7\n",
            "\tWithin-Cluster Variance: 0.219 Connected Cluster Dissimilarity: 8.81 Noise points ratio: 0.00576\n",
            "\n",
            "eps: 0.45 min_samples: 10\n",
            "\tWithin-Cluster Variance: 0.508 Connected Cluster Dissimilarity: 7.49 Noise points ratio: 0.13\n",
            "\n",
            "eps: 0.45 min_samples: 12\n",
            "\tWithin-Cluster Variance: 0.539 Connected Cluster Dissimilarity: 7.22 Noise points ratio: 0.167\n",
            "\n",
            "eps: 0.45 min_samples: 15\n",
            "\tWithin-Cluster Variance: 0.607 Connected Cluster Dissimilarity: 6.79 Noise points ratio: 0.244\n",
            "\n",
            "eps: 0.45 min_samples: 17\n",
            "\tWithin-Cluster Variance: 0.665 Connected Cluster Dissimilarity: 6.43 Noise points ratio: 0.313\n",
            "\n",
            "eps: 0.45 min_samples: 20\n",
            "\tWithin-Cluster Variance: 0.757 Connected Cluster Dissimilarity: 5.92 Noise points ratio: 0.435\n",
            "\n",
            "eps: 0.5 min_samples: 5\n",
            "\tWithin-Cluster Variance: 0.265 Connected Cluster Dissimilarity: 8.7 Noise points ratio: 0.000688\n",
            "\n",
            "eps: 0.5 min_samples: 7\n",
            "\tWithin-Cluster Variance: 0.26 Connected Cluster Dissimilarity: 8.69 Noise points ratio: 0.00314\n",
            "\n",
            "eps: 0.5 min_samples: 10\n",
            "\tWithin-Cluster Variance: 0.276 Connected Cluster Dissimilarity: 8.48 Noise points ratio: 0.0196\n",
            "\n",
            "eps: 0.5 min_samples: 12\n",
            "\tWithin-Cluster Variance: 0.523 Connected Cluster Dissimilarity: 7.38 Noise points ratio: 0.118\n",
            "\n",
            "eps: 0.5 min_samples: 15\n",
            "\tWithin-Cluster Variance: 0.56 Connected Cluster Dissimilarity: 7.08 Noise points ratio: 0.165\n",
            "\n",
            "eps: 0.5 min_samples: 17\n",
            "\tWithin-Cluster Variance: 0.597 Connected Cluster Dissimilarity: 6.81 Noise points ratio: 0.206\n",
            "\n",
            "eps: 0.5 min_samples: 20\n",
            "\tWithin-Cluster Variance: 0.665 Connected Cluster Dissimilarity: 6.34 Noise points ratio: 0.286\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from src.explanation.clustering.evaluation import apply_grid_search\n",
        "\n",
        "# Apply the grid search on a subset of the training set.\n",
        "apply_grid_search(\n",
        "    instances=y_train[:200],\n",
        "    eps_list=[.1, .15, .2, .25, .3, .35, .4, .45, .5],\n",
        "    min_samples_list=[5, 7, 10, 12, 15, 17, 20],\n",
        "    adj_distance_matrix=adj_distance_matrix,\n",
        "    temporal_distance_matrix=temporal_distance_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "yTw5SGaeNSFH"
      },
      "outputs": [],
      "source": [
        "# Set the best parameters based on the results of the grid search.\n",
        "\n",
        "EPS = .35\n",
        "MIN_SAMPLES = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fppd8gdSNSFH",
        "outputId": "eab6738d-b2aa-424a-c307-0842e9de4064"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Within-Cluster Variance on the test set: 0.156 Connected Cluster Dissimilarity on the test set: 9.61 Noise points ratio on the test set: 0.00614\n"
          ]
        }
      ],
      "source": [
        "from src.explanation.clustering.evaluation import get_dataset_clustering_scores\n",
        "\n",
        "(avg_within_cluster_variance, avg_connected_cluster_dissimilarity,\n",
        " avg_noise_ratio) = get_dataset_clustering_scores(\n",
        "     y_test, adj_distance_matrix, temporal_distance_matrix, EPS, MIN_SAMPLES)\n",
        "\n",
        "print(\n",
        "    'Within-Cluster Variance on the test set:',\n",
        "    f'{avg_within_cluster_variance:.3g}',\n",
        "    'Connected Cluster Dissimilarity on the test set:',\n",
        "    f'{avg_connected_cluster_dissimilarity:.3g}',\n",
        "    'Noise points ratio on the test set:', f'{avg_noise_ratio:.3g}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "rgh6eFLyNSFJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "DATA_DIR = os.path.join('..', 'data', 'pems-bay', 'explainable')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ehqtUhCJNSFJ"
      },
      "outputs": [],
      "source": [
        "from numpy import save\n",
        "from src.explanation.clustering.clustering import (\n",
        "    get_dataset_for_explainability)\n",
        "\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "(x_train_expl, y_train_expl,\n",
        " x_train_time_expl, y_train_time_expl) = get_dataset_for_explainability(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    x_train_time,\n",
        "    y_train_time,\n",
        "    EPS,\n",
        "    MIN_SAMPLES,\n",
        "    adj_distance_matrix,\n",
        "    temporal_distance_matrix,\n",
        "    total_samples=1_000)\n",
        "save(os.path.join(DATA_DIR, 'x_train.npy'), x_train_expl)\n",
        "save(os.path.join(DATA_DIR, 'y_train.npy'), y_train_expl)\n",
        "save(os.path.join(DATA_DIR, 'x_train_time.npy'), x_train_time_expl)\n",
        "save(os.path.join(DATA_DIR, 'y_train_time.npy'), y_train_time_expl)\n",
        "\n",
        "(x_val_expl, y_val_expl,\n",
        " x_val_time_expl, y_val_time_expl) = get_dataset_for_explainability(\n",
        "    x_val,\n",
        "    y_val,\n",
        "    x_val_time,\n",
        "    y_val_time,\n",
        "    EPS,\n",
        "    MIN_SAMPLES,\n",
        "    adj_distance_matrix,\n",
        "    temporal_distance_matrix,\n",
        "    total_samples=170)\n",
        "save(os.path.join(DATA_DIR, 'x_val.npy'), x_val_expl)\n",
        "save(os.path.join(DATA_DIR, 'y_val.npy'), y_val_expl)\n",
        "save(os.path.join(DATA_DIR, 'x_val_time.npy'), x_val_time_expl)\n",
        "save(os.path.join(DATA_DIR, 'y_val_time.npy'), y_val_time_expl)\n",
        "\n",
        "(x_test_expl, y_test_expl,\n",
        " x_test_time_expl, y_test_time_expl) = get_dataset_for_explainability(\n",
        "    x_test,\n",
        "    y_test,\n",
        "    x_test_time,\n",
        "    y_test_time,\n",
        "    EPS,\n",
        "    MIN_SAMPLES,\n",
        "    adj_distance_matrix,\n",
        "    temporal_distance_matrix,\n",
        "    total_samples=400)\n",
        "save(os.path.join(DATA_DIR, 'x_test.npy'), x_test_expl)\n",
        "save(os.path.join(DATA_DIR, 'y_test.npy'), y_test_expl)\n",
        "save(os.path.join(DATA_DIR, 'x_test_time.npy'), x_test_time_expl)\n",
        "save(os.path.join(DATA_DIR, 'y_test_time.npy'), y_test_time_expl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWR1ea1HNSFJ",
        "outputId": "84d3b180-9930-4a53-ed27-16f9ebbe5003"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset for explainability shapes: (999, 12, 325, 9) (999, 12, 325, 1)\n",
            "Validation dataset for explainability shapes: (168, 12, 325, 9) (168, 12, 325, 1)\n",
            "Test dataset for explainability shapes: (399, 12, 325, 9) (399, 12, 325, 1)\n"
          ]
        }
      ],
      "source": [
        "print('Train dataset for explainability shapes:',\n",
        "      x_train_expl.shape, y_train_expl.shape)\n",
        "print('Validation dataset for explainability shapes:',\n",
        "      x_val_expl.shape, y_val_expl.shape)\n",
        "print('Test dataset for explainability shapes:',\n",
        "      x_test_expl.shape, y_test_expl.shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
