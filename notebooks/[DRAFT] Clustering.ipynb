{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Set the main path in the root folder of the project.\n",
    "sys.path.append(os.path.join('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Settings for autoreloading.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.seed import set_random_seed\n",
    "\n",
    "# Set the random seed for deterministic operations.\n",
    "SEED = 42\n",
    "set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected device is: \"cuda\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set the device for training and querying the model.\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'The selected device is: \"{DEVICE}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_DATA_DIR = os.path.join('..', 'data', 'metr-la')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(os.path.join(BASE_DATA_DIR, 'processed', 'scaler.pkl'), 'rb') as f:\n",
    "    scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpatialTemporalGNN(\n",
       "  (encoder): Linear(in_features=9, out_features=64, bias=False)\n",
       "  (s_gnns): ModuleList(\n",
       "    (0-11): 12 x S_GNN(\n",
       "      (latent_encoder): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (1): Linear(in_features=64, out_features=32, bias=False)\n",
       "      )\n",
       "      (linear): Linear(in_features=64, out_features=64, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (hidden_s_gnns): ModuleList(\n",
       "    (0-10): 11 x S_GNN(\n",
       "      (latent_encoder): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (1): Linear(in_features=64, out_features=32, bias=False)\n",
       "      )\n",
       "      (linear): Linear(in_features=64, out_features=64, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (grus): ModuleList(\n",
       "    (0-11): 12 x GRU(\n",
       "      (z_x_linear): Linear(in_features=64, out_features=64, bias=False)\n",
       "      (z_h_linear): Linear(in_features=64, out_features=64, bias=False)\n",
       "      (r_x_linear): Linear(in_features=64, out_features=64, bias=False)\n",
       "      (r_h_linear): Linear(in_features=64, out_features=64, bias=False)\n",
       "      (h_x_linear): Linear(in_features=64, out_features=64, bias=False)\n",
       "      (h_h_linear): Linear(in_features=64, out_features=64, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (positional_encoder): PositionalEncoder()\n",
       "  (transformer): Transformer(\n",
       "    (queries_linear): Linear(in_features=64, out_features=64, bias=False)\n",
       "    (keys_linear): Linear(in_features=64, out_features=64, bias=False)\n",
       "    (values_linear): Linear(in_features=64, out_features=64, bias=False)\n",
       "    (normalization): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (normalization_out): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "    (feed_forward): Sequential(\n",
       "      (0): Linear(in_features=64, out_features=64, bias=False)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (prediction_head): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=64, bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=1, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.spatial_temporal_gnn.model import SpatialTemporalGNN\n",
    "from src.data.data_extraction import get_adjacency_matrix\n",
    "\n",
    "# Get the adjacency matrix\n",
    "adj_matrix_structure = get_adjacency_matrix(\n",
    "    os.path.join(BASE_DATA_DIR, 'adj_mx_metr_la.pkl'))\n",
    "\n",
    "# Get the header of the adjacency matrix and the matrix itself.\n",
    "header, node_ids_dict, adj_matrix = adj_matrix_structure\n",
    "\n",
    "spatial_temporal_gnn = SpatialTemporalGNN(9, 1, 12, 12, adj_matrix, DEVICE, 64)\n",
    "\n",
    "stgnn_checkpoints_path = os.path.join('..', 'models', 'checkpoints',\n",
    "                                      'st_gnn_metr_la.pth')\n",
    "\n",
    "stgnn_checkpoints = torch.load(stgnn_checkpoints_path)\n",
    "spatial_temporal_gnn.load_state_dict(stgnn_checkpoints['model_state_dict'])\n",
    "\n",
    "spatial_temporal_gnn.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.data_extraction import get_locations_dataframe\n",
    "\n",
    "# Get the dataframe containing the latitude and longitude of each sensor.\n",
    "locations_df = get_locations_dataframe(\n",
    "    os.path.join(BASE_DATA_DIR, 'graph_sensor_locations_metr_la.csv'),\n",
    "    has_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_ids_dict\n",
    "node_pos_dict = { i: id for id, i in node_ids_dict.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from src.spatial_temporal_gnn.prediction import predict\n",
    "\n",
    "x_train = np.load(os.path.join(BASE_DATA_DIR, 'processed', 'x_train.npy'))\n",
    "y_train = predict(spatial_temporal_gnn, x_train, scaler, DEVICE)\n",
    "x_val = np.load(os.path.join(BASE_DATA_DIR, 'processed', 'x_val.npy'))\n",
    "y_val = predict(spatial_temporal_gnn, x_val, scaler, DEVICE)\n",
    "x_test = np.load(os.path.join(BASE_DATA_DIR, 'processed', 'x_test.npy'))\n",
    "y_test = predict(spatial_temporal_gnn, x_test, scaler, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPH_TO_KMH_FACTOR = 1.609344\n",
    "y_train = y_train * MPH_TO_KMH_FACTOR\n",
    "y_val = y_val * MPH_TO_KMH_FACTOR\n",
    "y_test = y_test * MPH_TO_KMH_FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MPH_TO_KMH_FACTOR = 1.609344\n",
    "# sample = y_test[100] * MPH_TO_KMH_FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, n_timesteps, n_nodes, _ = y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_reshaped = sample.reshape(-2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_total_nodes = sample_reshaped.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.std(adj_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjacency Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_matrix_expanded = np.concatenate(\n",
    "    [np.concatenate([adj_matrix] * n_timesteps, axis=0)] * n_timesteps, axis=1)\n",
    "\n",
    "distance_adj_matrix = 1 - adj_matrix_expanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2484, 2484)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_adj_matrix.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Line-space the time steps between 0 and 1.\n",
    "linespaced_time_steps = np.linspace(0, 1, n_timesteps)\n",
    "\n",
    "# Repeat each time step for each node.\n",
    "extended_time_steps = np.repeat(linespaced_time_steps, n_nodes)\n",
    "\n",
    "# Add dummy dimension to the array.\n",
    "extended_time_steps = np.expand_dims(extended_time_steps, axis=1)\n",
    "\n",
    "distance_time_matrix = cdist(extended_time_steps, extended_time_steps, 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2484, 2484)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_time_matrix.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "def get_clusters(\n",
    "    instance: np.ndarray, adj_distance_matrix: np.ndarray,\n",
    "    time_distance_matrix: np.ndarray, eps: float,\n",
    "    min_samples: int, speed_distance_weight: float = 3) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get the clusters of the given instance using the DBSCAN algorithm.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    instance : ndarray\n",
    "        The spatial-temporal graph instance to cluster.\n",
    "    adj_distance_matrix : ndarray\n",
    "        The adjacency matrix of the nodes in the graph measured in distance\n",
    "        between 0 and 1.\n",
    "    time_distance_matrix : ndarray\n",
    "        The matrix measuring the distance between the time steps\n",
    "        of the nodes in the graph between 0 and 1.\n",
    "    eps : float\n",
    "        The maximum distance between two samples for one to be considered\n",
    "        as in the neighborhood of the other.\n",
    "    min_samples : int\n",
    "        The number of samples in a neighborhood for a point for it to be\n",
    "        considered as a core point.\n",
    "    speed_distance_weight : float, optional\n",
    "        The weight of the speed distance in the clustering process,\n",
    "        by default 3.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        The clusters of the given instance.\n",
    "    \"\"\"\n",
    "    n_timesteps, n_nodes, _ = instance.shape\n",
    "\n",
    "    # Reshape the instance to be a column vector.\n",
    "    instance = instance.reshape(-2, 1)\n",
    "\n",
    "    # Compute the distance matrix between the speed of the nodes in the graph.\n",
    "    speed_distance_matrix = cdist(instance, instance, 'euclidean')\n",
    "    # Normalize the distance matrix between 0 and 1.\n",
    "    speed_distance_matrix /= np.max(speed_distance_matrix)\n",
    "\n",
    "    # Compute the weighted distance matrix between the nodes in the graph\n",
    "    # in terms of speed and the spatial and temporal distances.\n",
    "    distance_matrix = speed_distance_matrix * speed_distance_weight +\\\n",
    "        adj_distance_matrix + time_distance_matrix\n",
    "\n",
    "    # Normalize the distance matrix between 0 and 1.\n",
    "    distance_matrix /= np.max(distance_matrix)\n",
    "    # Set the distance between nodes that are not connected to the maximum.\n",
    "    distance_matrix[distance_adj_matrix == 1] = 1_000\n",
    "\n",
    "    # Compute the clusters of the given instance using the DBSCAN algorithm.\n",
    "    dbscan = DBSCAN(metric='precomputed', eps=eps, min_samples=min_samples,\n",
    "                    n_jobs=-1)\n",
    "    clusters = dbscan.fit_predict(distance_matrix)\n",
    "\n",
    "    # Add a dummy dimension to the clusters array.\n",
    "    clusters = np.expand_dims(clusters, axis=1)\n",
    "\n",
    "    # Reshape the clusters array to have the same shape as the instance.\n",
    "    clusters = clusters.reshape(n_timesteps, n_nodes, 1)\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_within_clusters_variance(\n",
    "    instance: np.ndarray, clusters: np.ndarray) -> float:\n",
    "    \"\"\"Get the Within-Cluster Variance metric of the clusters\n",
    "    obtained on the given instance in terms of speed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    instance : ndarray\n",
    "        The spatial-temporal graph instance on which the clusters\n",
    "        are evaluated.\n",
    "    clusters : ndarray\n",
    "        The clusters obtained on the given instance.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The Within-Cluster Variance metric result.\n",
    "    \"\"\"\n",
    "    # Set the intial value of the numerator sum to 0.\n",
    "    numerator_sum = 0.\n",
    "    # Set the initial value of the total number of nodes to 0.\n",
    "    total_node_number = 0.\n",
    "\n",
    "    for c in np.unique(clusters):\n",
    "        # Get the sub-sample of the nodes in the graph that belong to the\n",
    "        # current cluster.\n",
    "        sub_sample = instance[clusters == c]\n",
    "        # Get the length of the sub-sample.\n",
    "        len_sub_sample = len(sub_sample)\n",
    "        # Update the total nominator sum.\n",
    "        numerator_sum += np.var(sub_sample) * len_sub_sample\n",
    "        # Update the total number of nodes with the length of the sub-sample.\n",
    "        total_node_number += len_sub_sample\n",
    "\n",
    "    return numerator_sum / (total_node_number * np.var(instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def are_clusters_connected(\n",
    "    clusters: np.ndarray, cluster_1: int, cluster_2: int,\n",
    "    adj_matrix: np.ndarray) -> bool:\n",
    "    \"\"\"\n",
    "    Check whether the given clusters are connected or not, by\n",
    "    observing whethere there are node spatially or temporally\n",
    "    connected between the two clusters.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    clusters : ndarray\n",
    "        The clustered instance.\n",
    "    cluster_1 : int\n",
    "        The ID of the first cluster.\n",
    "    cluster_2 : int\n",
    "        The ID of the second cluster.\n",
    "    adj_matrix : ndarray\n",
    "        The adjacency matrix of the nodes in the graph.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        Whether the given clusters are connected or not.\n",
    "    \"\"\"\n",
    "    # Get the indices of the nodes that belong to the two clusters.\n",
    "    # indices = (list of timesteps, list of nodes).\n",
    "    indices_cluster_1 = np.where(clusters == cluster_1)[:-1]\n",
    "    indices_cluster_2 = np.where(clusters == cluster_2)[:-1]\n",
    "\n",
    "    # Zip the indices of the nodes that belong to the two clusters.\n",
    "    zip_indices_cluster_1 = zip(indices_cluster_1[0], indices_cluster_1[1])\n",
    "    zip_indices_cluster_2 = zip(indices_cluster_2[0], indices_cluster_2[1])\n",
    "\n",
    "    for indices_cluster_1 in zip_indices_cluster_1:\n",
    "        for indices_cluster_2 in zip_indices_cluster_2:\n",
    "            # Get the indices of the timestep and the nodes.\n",
    "            timestep_0, node_0 = indices_cluster_1\n",
    "            timestep_1, node_1 = indices_cluster_2\n",
    "            # Check if the nodes are spatially connected in the same timestep.\n",
    "            if timestep_0 == timestep_1 and (adj_matrix[node_0, node_1] > 0 or adj_matrix[node_1, node_0] > 0):\n",
    "                return True\n",
    "            # Check if the nodes are the same and temporally connected.\n",
    "            if node_0 == node_1 and np.abs(timestep_0 - timestep_1) == 1:\n",
    "                return True\n",
    "    # If no connection is found, return False.\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.abs(adj_matrix-adj_matrix.T) < 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7174379"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_matrix[2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.abs(1 - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_connected_cluster_dissimilarity(\n",
    "    instance: np.ndarray, clusters: np.ndarray,\n",
    "    adj_matrix: np.ndarray) -> float:\n",
    "    \"\"\"Get the Connected Cluster Dissimilarity metric of the clusters\n",
    "    obtained on the given instance in terms of speed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    instance : ndarray\n",
    "        The spatial-temporal graph instance on which the clusters\n",
    "        are evaluated.\n",
    "    clusters : ndarray\n",
    "        The clusters obtained on the given instance.\n",
    "    adj_matrix : ndarray\n",
    "        The adjacency matrix of the nodes in the graph.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The Connected Cluster Dissimilarity metric result.\n",
    "    \"\"\"\n",
    "    # Get the total unique cluster IDs.\n",
    "    total_clusters = [c for c in np.unique(clusters) if c != -1]\n",
    "\n",
    "    # Set the initial value of the denominator sum to 0.\n",
    "    denominator_sum = 0.\n",
    "    # Set the initial value of the nominator sum to 0.\n",
    "    nominator_sum = 0.\n",
    "\n",
    "    for i, c1 in enumerate(total_clusters):\n",
    "        for c2 in total_clusters[i+1:]:\n",
    "            # If the two clusters are not connected, continue the loop.\n",
    "            #if not are_clusters_connected(clusters, c1, c2, adj_matrix):\n",
    "            #    continue\n",
    "            # Get the sub-samples of the nodes in the graph that belong to the\n",
    "            # current clusters.\n",
    "            sub_sample1 = instance[clusters == c1]\n",
    "            sub_sample2 = instance[clusters == c2]\n",
    "            # Get the length of the sub-samples.\n",
    "            len_sub_sample1 = len(sub_sample1)\n",
    "            len_sub_sample2 = len(sub_sample2)\n",
    "            # Compute the square root of the product of the lengths.\n",
    "            sqrt_lens = np.sqrt(len_sub_sample1 * len_sub_sample2)\n",
    "            # Compute the absolute difference between the means.\n",
    "            abs_mean_diff = np.abs(np.mean(sub_sample1) - np.mean(sub_sample2))\n",
    "            # Update the nominator sum.\n",
    "            nominator_sum += sqrt_lens * abs_mean_diff\n",
    "            # Update the denominator sum.\n",
    "            denominator_sum += sqrt_lens\n",
    "\n",
    "    return nominator_sum / denominator_sum if denominator_sum > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within-Cluster Variance: 0.06927178837674024\n",
      "Connected Cluster Dissimilarity: 18.55007861951367\n"
     ]
    }
   ],
   "source": [
    "sample = y_test[100]\n",
    " \n",
    "clusters = get_clusters(sample, distance_adj_matrix, distance_time_matrix,\n",
    "                        eps=.1, min_samples=6)\n",
    "\n",
    "print('Within-Cluster Variance:', get_within_clusters_variance(sample, clusters))\n",
    "print('Connected Cluster Dissimilarity:', get_connected_cluster_dissimilarity(sample, clusters, adj_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "parameter_grid = ParameterGrid({\n",
    "    'eps': [.1, .2, .3, .4],\n",
    "    'min_samples': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parameter_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps: 0.1 min_samples: 3\n",
      "\tWithin-Cluster Variance: 0.113 Connected Cluster Dissimilarity: 15.4\n",
      "\n",
      "eps: 0.1 min_samples: 4\n",
      "\tWithin-Cluster Variance: 0.116 Connected Cluster Dissimilarity: 15.4\n",
      "\n",
      "eps: 0.1 min_samples: 5\n",
      "\tWithin-Cluster Variance: 0.121 Connected Cluster Dissimilarity: 15.3\n",
      "\n",
      "eps: 0.1 min_samples: 6\n",
      "\tWithin-Cluster Variance: 0.126 Connected Cluster Dissimilarity: 15.2\n",
      "\n",
      "eps: 0.1 min_samples: 7\n",
      "\tWithin-Cluster Variance: 0.128 Connected Cluster Dissimilarity: 15.2\n",
      "\n",
      "eps: 0.1 min_samples: 8\n",
      "\tWithin-Cluster Variance: 0.129 Connected Cluster Dissimilarity: 15.1\n",
      "\n",
      "eps: 0.1 min_samples: 9\n",
      "\tWithin-Cluster Variance: 0.138 Connected Cluster Dissimilarity: 14.8\n",
      "\n",
      "eps: 0.1 min_samples: 10\n",
      "\tWithin-Cluster Variance: 0.166 Connected Cluster Dissimilarity: 14.2\n",
      "\n",
      "eps: 0.1 min_samples: 11\n",
      "\tWithin-Cluster Variance: 0.253 Connected Cluster Dissimilarity: 13\n",
      "\n",
      "eps: 0.1 min_samples: 12\n",
      "\tWithin-Cluster Variance: 0.421 Connected Cluster Dissimilarity: 12.9\n",
      "\n",
      "eps: 0.2 min_samples: 3\n",
      "\tWithin-Cluster Variance: 0.495 Connected Cluster Dissimilarity: 20.5\n",
      "\n",
      "eps: 0.2 min_samples: 4\n",
      "\tWithin-Cluster Variance: 0.494 Connected Cluster Dissimilarity: 20.4\n",
      "\n",
      "eps: 0.2 min_samples: 5\n",
      "\tWithin-Cluster Variance: 0.494 Connected Cluster Dissimilarity: 20.4\n",
      "\n",
      "eps: 0.2 min_samples: 6\n",
      "\tWithin-Cluster Variance: 0.491 Connected Cluster Dissimilarity: 20.5\n",
      "\n",
      "eps: 0.2 min_samples: 7\n",
      "\tWithin-Cluster Variance: 0.484 Connected Cluster Dissimilarity: 20.5\n",
      "\n",
      "eps: 0.2 min_samples: 8\n",
      "\tWithin-Cluster Variance: 0.48 Connected Cluster Dissimilarity: 20.6\n",
      "\n",
      "eps: 0.2 min_samples: 9\n",
      "\tWithin-Cluster Variance: 0.475 Connected Cluster Dissimilarity: 20.7\n",
      "\n",
      "eps: 0.2 min_samples: 10\n",
      "\tWithin-Cluster Variance: 0.467 Connected Cluster Dissimilarity: 20.7\n",
      "\n",
      "eps: 0.2 min_samples: 11\n",
      "\tWithin-Cluster Variance: 0.458 Connected Cluster Dissimilarity: 20.8\n",
      "\n",
      "eps: 0.2 min_samples: 12\n",
      "\tWithin-Cluster Variance: 0.447 Connected Cluster Dissimilarity: 20.9\n",
      "\n",
      "eps: 0.3 min_samples: 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\riccardo\\Desktop\\Verbal-Explanation-of-Graph-Neural-Networks-for-Traffic-Forecasting\\notebooks\\Creating Explanation Instances on Metr-LA.ipynb Cell 36\u001b[0m in \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/riccardo/Desktop/Verbal-Explanation-of-Graph-Neural-Networks-for-Traffic-Forecasting/notebooks/Creating%20Explanation%20Instances%20on%20Metr-LA.ipynb#X50sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39meps:\u001b[39m\u001b[39m'\u001b[39m, p[\u001b[39m'\u001b[39m\u001b[39meps\u001b[39m\u001b[39m'\u001b[39m], \u001b[39m'\u001b[39m\u001b[39mmin_samples:\u001b[39m\u001b[39m'\u001b[39m, p[\u001b[39m'\u001b[39m\u001b[39mmin_samples\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/riccardo/Desktop/Verbal-Explanation-of-Graph-Neural-Networks-for-Traffic-Forecasting/notebooks/Creating%20Explanation%20Instances%20on%20Metr-LA.ipynb#X50sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m instance \u001b[39min\u001b[39;00m y_train[:\u001b[39m500\u001b[39m]:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/riccardo/Desktop/Verbal-Explanation-of-Graph-Neural-Networks-for-Traffic-Forecasting/notebooks/Creating%20Explanation%20Instances%20on%20Metr-LA.ipynb#X50sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     clusters \u001b[39m=\u001b[39m get_clusters(instance, distance_adj_matrix, distance_time_matrix,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/riccardo/Desktop/Verbal-Explanation-of-Graph-Neural-Networks-for-Traffic-Forecasting/notebooks/Creating%20Explanation%20Instances%20on%20Metr-LA.ipynb#X50sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                             eps\u001b[39m=\u001b[39;49mp[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m], min_samples\u001b[39m=\u001b[39;49mp[\u001b[39m'\u001b[39;49m\u001b[39mmin_samples\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/riccardo/Desktop/Verbal-Explanation-of-Graph-Neural-Networks-for-Traffic-Forecasting/notebooks/Creating%20Explanation%20Instances%20on%20Metr-LA.ipynb#X50sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     within_cluster_variance \u001b[39m=\u001b[39m get_within_clusters_variance(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/riccardo/Desktop/Verbal-Explanation-of-Graph-Neural-Networks-for-Traffic-Forecasting/notebooks/Creating%20Explanation%20Instances%20on%20Metr-LA.ipynb#X50sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         instance, clusters)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/riccardo/Desktop/Verbal-Explanation-of-Graph-Neural-Networks-for-Traffic-Forecasting/notebooks/Creating%20Explanation%20Instances%20on%20Metr-LA.ipynb#X50sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     connected_cluster_dissimilarity \u001b[39m=\u001b[39m get_connected_cluster_dissimilarity(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/riccardo/Desktop/Verbal-Explanation-of-Graph-Neural-Networks-for-Traffic-Forecasting/notebooks/Creating%20Explanation%20Instances%20on%20Metr-LA.ipynb#X50sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         instance, clusters, adj_matrix)\n",
      "\u001b[1;32mc:\\Users\\riccardo\\Desktop\\Verbal-Explanation-of-Graph-Neural-Networks-for-Traffic-Forecasting\\notebooks\\Creating Explanation Instances on Metr-LA.ipynb Cell 36\u001b[0m in \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/riccardo/Desktop/Verbal-Explanation-of-Graph-Neural-Networks-for-Traffic-Forecasting/notebooks/Creating%20Explanation%20Instances%20on%20Metr-LA.ipynb#X50sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m distance_matrix \u001b[39m=\u001b[39m speed_distance_matrix \u001b[39m*\u001b[39m speed_distance_weight \u001b[39m+\u001b[39m\\\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/riccardo/Desktop/Verbal-Explanation-of-Graph-Neural-Networks-for-Traffic-Forecasting/notebooks/Creating%20Explanation%20Instances%20on%20Metr-LA.ipynb#X50sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     adj_distance_matrix \u001b[39m+\u001b[39m time_distance_matrix\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/riccardo/Desktop/Verbal-Explanation-of-Graph-Neural-Networks-for-Traffic-Forecasting/notebooks/Creating%20Explanation%20Instances%20on%20Metr-LA.ipynb#X50sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m# Normalize the distance matrix between 0 and 1.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/riccardo/Desktop/Verbal-Explanation-of-Graph-Neural-Networks-for-Traffic-Forecasting/notebooks/Creating%20Explanation%20Instances%20on%20Metr-LA.ipynb#X50sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m distance_matrix \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mmax(distance_matrix)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/riccardo/Desktop/Verbal-Explanation-of-Graph-Neural-Networks-for-Traffic-Forecasting/notebooks/Creating%20Explanation%20Instances%20on%20Metr-LA.ipynb#X50sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39m# Set the distance between nodes that are not connected to the maximum.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/riccardo/Desktop/Verbal-Explanation-of-Graph-Neural-Networks-for-Traffic-Forecasting/notebooks/Creating%20Explanation%20Instances%20on%20Metr-LA.ipynb#X50sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m distance_matrix[distance_adj_matrix \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1_000\u001b[39m\n",
      "File \u001b[1;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mamax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#from tqdm import tqdm\n",
    "\n",
    "for p in parameter_grid:\n",
    "    total_within_cluster_variance = 0.\n",
    "    total_connected_cluster_dissimilarity = 0.\n",
    "    print('eps:', p['eps'], 'min_samples:', p['min_samples'])\n",
    "    for instance in y_train[:500]:\n",
    "        clusters = get_clusters(instance, distance_adj_matrix, distance_time_matrix,\n",
    "                                eps=p['eps'], min_samples=p['min_samples'])\n",
    "        within_cluster_variance = get_within_clusters_variance(\n",
    "            instance, clusters)\n",
    "        connected_cluster_dissimilarity = get_connected_cluster_dissimilarity(\n",
    "            instance, clusters, adj_matrix)\n",
    "        total_within_cluster_variance += within_cluster_variance\n",
    "        total_connected_cluster_dissimilarity += connected_cluster_dissimilarity\n",
    "\n",
    "    avg_within_cluster_variance = total_within_cluster_variance / len(y_train[:500])\n",
    "    avg_connected_cluster_dissimilarity = total_connected_cluster_dissimilarity / len(y_train[:500])\n",
    "    print('\\tWithin-Cluster Variance:', f'{avg_within_cluster_variance:.3g}', \n",
    "          'Connected Cluster Dissimilarity:', f'{avg_connected_cluster_dissimilarity:.3g}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = .2\n",
    "MIN_SAMPLES = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation with eps: 0.2 min_samples: 6\n",
      "\tWithin-Cluster Variance: 0.159 Connected Cluster Dissimilarity: 7.81\n"
     ]
    }
   ],
   "source": [
    "total_within_cluster_variance = 0.\n",
    "total_connected_cluster_dissimilarity = 0.\n",
    "print('Test set evaluation with eps:', EPS, 'min_samples:', MIN_SAMPLES)\n",
    "for instance in y_test:\n",
    "    clusters = get_clusters(instance, distance_adj_matrix, distance_time_matrix,\n",
    "                            eps=EPS, min_samples=MIN_SAMPLES)\n",
    "    within_cluster_variance = get_within_clusters_variance(instance, clusters)\n",
    "    connected_cluster_dissimilarity = get_connected_cluster_dissimilarity(\n",
    "        instance, clusters, adj_matrix)\n",
    "    total_within_cluster_variance += within_cluster_variance\n",
    "    total_connected_cluster_dissimilarity += connected_cluster_dissimilarity\n",
    "\n",
    "avg_within_cluster_variance = total_within_cluster_variance / len(y_train)\n",
    "avg_connected_cluster_dissimilarity = total_connected_cluster_dissimilarity / len(y_train)\n",
    "print('\\tWithin-Cluster Variance:', f'{avg_within_cluster_variance:.3g}', \n",
    "        'Connected Cluster Dissimilarity:', f'{avg_connected_cluster_dissimilarity:.3g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = y_test[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08153912369307907\n",
      "19.93397202202428\n"
     ]
    }
   ],
   "source": [
    "clusters = get_clusters(instance, distance_adj_matrix, distance_time_matrix,\n",
    "                        eps=0.2, min_samples=10)\n",
    "\n",
    "print(get_within_clusters_variance(instance, clusters))\n",
    "print(get_connected_cluster_dissimilarity(instance, clusters, adj_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0  1  2  3  4  5]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(clusters.squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters found: 7\n"
     ]
    }
   ],
   "source": [
    "print('Number of clusters found:', len(np.unique(clusters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.concatenate((sample, clusters), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "def get_node_values_with_location_dataframe(\n",
    "    node_values: np.ndarray, node_pos_dict: Dict[int, str],\n",
    "    locations_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Get a pandas dataframe from a pandas dataframe of node speed values\n",
    "    and a pandas dataframe of node locations. The resulting dataframe\n",
    "    has for each timestamp the value of the metric for each node and\n",
    "    the location of the node in the form of latitude and longitude.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    node_values : ndarray\n",
    "        The numpy array containing the values of the cluster and speed of\n",
    "        each node for each timestamp.\n",
    "    locations_df : DataFrame\n",
    "        The dataframe containing the location of each node.\n",
    "    metric_name : str\n",
    "        The name of the metric that will be used in the resulting dataframe.\n",
    "    turn_datetimes_to_timestamp : bool\n",
    "        Whether to turn the datetimes to timestamp or not.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        The resulting dataframe containing the values of the metric for\n",
    "        each node and the location of the node in the form of latitude\n",
    "        and longitude.\n",
    "    \"\"\"\n",
    "    nodes_information = []\n",
    "    \n",
    "    for time_idx, node_matrix in enumerate(node_values):\n",
    "        for node_idx, features in enumerate(node_matrix):\n",
    "            node_id = node_pos_dict[node_idx]\n",
    "\n",
    "            latitude = locations_df.loc[\n",
    "                locations_df['sensor_id'] == node_id].latitude.values[0]\n",
    "            longitude = locations_df.loc[\n",
    "                locations_df['sensor_id'] == node_id].longitude.values[0]\n",
    "    \n",
    "            nodes_information.append(\n",
    "                [node_id,\n",
    "                 latitude,\n",
    "                 longitude,\n",
    "                 features[1],\n",
    "                 features[0],\n",
    "                 time_idx])\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'sensor_id': [n[0] for n in nodes_information],\n",
    "        'latitude': [n[1] for n in nodes_information],\n",
    "        'longitude': [n[2] for n in nodes_information],\n",
    "        'cluster': [n[3] for n in nodes_information],\n",
    "        'speed': [n[4] for n in nodes_information],\n",
    "        'datetime': [n[5] for n in nodes_information]\n",
    "    })\n",
    "    df['cluster'] = df['cluster'].astype(int)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df_with_clusters = get_node_values_with_location_dataframe(\n",
    "    sample, node_pos_dict, locations_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>cluster</th>\n",
       "      <th>speed</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>773869</td>\n",
       "      <td>34.15497</td>\n",
       "      <td>-118.31829</td>\n",
       "      <td>0</td>\n",
       "      <td>105.516815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>767541</td>\n",
       "      <td>34.11621</td>\n",
       "      <td>-118.23799</td>\n",
       "      <td>0</td>\n",
       "      <td>106.308350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>767542</td>\n",
       "      <td>34.11641</td>\n",
       "      <td>-118.23819</td>\n",
       "      <td>0</td>\n",
       "      <td>110.634773</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>717447</td>\n",
       "      <td>34.07248</td>\n",
       "      <td>-118.26772</td>\n",
       "      <td>0</td>\n",
       "      <td>81.586983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>717446</td>\n",
       "      <td>34.07142</td>\n",
       "      <td>-118.26572</td>\n",
       "      <td>0</td>\n",
       "      <td>44.713619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sensor_id  latitude  longitude  cluster       speed  datetime\n",
       "0    773869  34.15497 -118.31829        0  105.516815         0\n",
       "1    767541  34.11621 -118.23799        0  106.308350         0\n",
       "2    767542  34.11641 -118.23819        0  110.634773         0\n",
       "3    717447  34.07248 -118.26772        0   81.586983         0\n",
       "4    717446  34.07142 -118.26572        0   44.713619         0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_df_with_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keplergl.keplergl import KeplerGl\n",
    "\n",
    "m = KeplerGl(height=800, show_docs=False, data={'data': location_df_with_clusters})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from src.data.data_analysis import show_kepler_map\n",
    "\n",
    "print('Metr-LA speed clusters on the first Monday:')\n",
    "show_kepler_map(location_df_with_clusters, None)''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd526ad59d0d432894aa40cb750fe4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(data={'data':      sensor_id  latitude  longitude  cluster       speed  datetime\n",
       "0       773869  34.1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def are_clusters_connected(clusters, c1, c2, adj_matrix):\n",
    "    cluster_nodes_0 = np.where(clusters == c1)[:-1]\n",
    "    cluster_nodes_1 = np.where(clusters == c2)[:-1]\n",
    "\n",
    "    for i in zip(cluster_nodes_0[0], cluster_nodes_0[1], cluster_nodes_1[0], cluster_nodes_1[1]):\n",
    "        # The nodes are spatially connected.\n",
    "        if adj_matrix[i[1], i[3]] > 0:\n",
    "            return True\n",
    "        # The nodes are the same ones and there is a temporal distance of 1.\n",
    "        if i[1] == i[3] and np.abs(i[0] - i[2]) == 1:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.855244937941013"
      ]
     },
     "execution_count": 603,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_clusters = np.unique(clusters)\n",
    "\n",
    "denominator_sum = 0.\n",
    "nominator_sum = 0.\n",
    "\n",
    "for i, c1 in enumerate(total_clusters):\n",
    "    for cluster_2 in total_clusters[i+1:]:\n",
    "        if not are_clusters_connected(clusters, c1, cluster_2, adj_matrix):\n",
    "            continue\n",
    "        sub_sample1 = sample[clusters == c1]\n",
    "        sub_sample2 = sample[clusters == cluster_2]\n",
    "        len_sub_sample1 = len(sub_sample1)\n",
    "        len_sub_sample2 = len(sub_sample2)\n",
    "        sqrt_lens = np.sqrt(len_sub_sample1 * len_sub_sample2)\n",
    "        nominator_sum += sqrt_lens * np.abs(np.mean(sub_sample1) - np.mean(sub_sample2))\n",
    "        denominator_sum += sqrt_lens\n",
    "\n",
    "nominator_sum / denominator_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 207, 2)\n"
     ]
    }
   ],
   "source": [
    "print(sample_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "def get_node_values_with_location_dataframe(\n",
    "    node_values: np.ndarray, node_pos_dict: Dict[int, str],\n",
    "    locations_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Get a pandas dataframe from a pandas dataframe of node speed values\n",
    "    and a pandas dataframe of node locations. The resulting dataframe\n",
    "    has for each timestamp the value of the metric for each node and\n",
    "    the location of the node in the form of latitude and longitude.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    node_values : ndarray\n",
    "        The numpy array containing the values of the cluster and speed of\n",
    "        each node for each timestamp.\n",
    "    locations_df : DataFrame\n",
    "        The dataframe containing the location of each node.\n",
    "    metric_name : str\n",
    "        The name of the metric that will be used in the resulting dataframe.\n",
    "    turn_datetimes_to_timestamp : bool\n",
    "        Whether to turn the datetimes to timestamp or not.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        The resulting dataframe containing the values of the metric for\n",
    "        each node and the location of the node in the form of latitude\n",
    "        and longitude.\n",
    "    \"\"\"\n",
    "    nodes_information = []\n",
    "    \n",
    "    for time_idx, node_matrix in enumerate(node_values):\n",
    "        for node_idx, features in enumerate(node_matrix):\n",
    "            node_id = node_pos_dict[node_idx]\n",
    "\n",
    "            latitude = locations_df.loc[\n",
    "                locations_df['sensor_id'] == node_id].latitude.values[0]\n",
    "            longitude = locations_df.loc[\n",
    "                locations_df['sensor_id'] == node_id].longitude.values[0]\n",
    "    \n",
    "            nodes_information.append(\n",
    "                [node_id,\n",
    "                 latitude,\n",
    "                 longitude,\n",
    "                 features[1],\n",
    "                 features[0],\n",
    "                 time_idx])\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'sensor_id': [n[0] for n in nodes_information],\n",
    "        'latitude': [n[1] for n in nodes_information],\n",
    "        'longitude': [n[2] for n in nodes_information],\n",
    "        'cluster': [n[3] for n in nodes_information],\n",
    "        'speed': [n[4] for n in nodes_information],\n",
    "        'datetime': [n[5] for n in nodes_information]\n",
    "    })\n",
    "    df['cluster'] = df['cluster'].astype(int)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df_with_clusters = get_node_values_with_location_dataframe(\n",
    "    sample_, node_pos_dict, locations_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,  48,  28,  63,   4,  64,  65,  66,  67,  -1,\n",
       "         5,   6,  50,   7,   8,  14,  68,   9,  10,  69,  25,  51,  70,\n",
       "        61,  71,  72,  27,  11,  73,  12,  13,  74,  75,  76,  77,  78,\n",
       "        79,  80,  81,  82,  52,  15,  16,  18,  17,  53,  83,  84,  85,\n",
       "        32,  19,  44,  20,  86,  87,  21,  22,  23,  54,  55,  24,  88,\n",
       "        26,  89,  90,  91,  92,  29,  39,  93,  94,  30,  56,  95,  31,\n",
       "        96,  57,  97,  33,  58,  34,  35,  98,  36,  37,  99,  59,  47,\n",
       "        38,  60,  40, 100,  41, 101, 102, 103,  42, 104, 105, 106, 107,\n",
       "       108,  43, 109, 110, 111,  45, 112, 113, 114, 115,  46, 116, 117,\n",
       "        62, 118, 119, 120, 121, 122, 123,  49, 124, 125])"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_df_with_clusters['cluster'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location_df_with_clusters['cluster'] = location_df_with_clusters['cluster'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>cluster</th>\n",
       "      <th>speed</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>773869</td>\n",
       "      <td>34.15497</td>\n",
       "      <td>-118.31829</td>\n",
       "      <td>0</td>\n",
       "      <td>105.516815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>767541</td>\n",
       "      <td>34.11621</td>\n",
       "      <td>-118.23799</td>\n",
       "      <td>1</td>\n",
       "      <td>106.308350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>767542</td>\n",
       "      <td>34.11641</td>\n",
       "      <td>-118.23819</td>\n",
       "      <td>2</td>\n",
       "      <td>110.634773</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>717447</td>\n",
       "      <td>34.07248</td>\n",
       "      <td>-118.26772</td>\n",
       "      <td>3</td>\n",
       "      <td>81.586983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>717446</td>\n",
       "      <td>34.07142</td>\n",
       "      <td>-118.26572</td>\n",
       "      <td>48</td>\n",
       "      <td>44.713619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>717592</td>\n",
       "      <td>34.14604</td>\n",
       "      <td>-118.22430</td>\n",
       "      <td>121</td>\n",
       "      <td>100.792572</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>717595</td>\n",
       "      <td>34.14163</td>\n",
       "      <td>-118.18290</td>\n",
       "      <td>122</td>\n",
       "      <td>109.369804</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>772168</td>\n",
       "      <td>34.16542</td>\n",
       "      <td>-118.47985</td>\n",
       "      <td>123</td>\n",
       "      <td>95.773941</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>718141</td>\n",
       "      <td>34.15133</td>\n",
       "      <td>-118.37456</td>\n",
       "      <td>19</td>\n",
       "      <td>106.050285</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>769373</td>\n",
       "      <td>34.10262</td>\n",
       "      <td>-118.31747</td>\n",
       "      <td>49</td>\n",
       "      <td>82.925262</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2484 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sensor_id  latitude  longitude  cluster       speed  datetime\n",
       "0       773869  34.15497 -118.31829        0  105.516815         0\n",
       "1       767541  34.11621 -118.23799        1  106.308350         0\n",
       "2       767542  34.11641 -118.23819        2  110.634773         0\n",
       "3       717447  34.07248 -118.26772        3   81.586983         0\n",
       "4       717446  34.07142 -118.26572       48   44.713619         0\n",
       "...        ...       ...        ...      ...         ...       ...\n",
       "2479    717592  34.14604 -118.22430      121  100.792572        11\n",
       "2480    717595  34.14163 -118.18290      122  109.369804        11\n",
       "2481    772168  34.16542 -118.47985      123   95.773941        11\n",
       "2482    718141  34.15133 -118.37456       19  106.050285        11\n",
       "2483    769373  34.10262 -118.31747       49   82.925262        11\n",
       "\n",
       "[2484 rows x 6 columns]"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_df_with_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keplergl.keplergl import KeplerGl\n",
    "\n",
    "m = KeplerGl(height=800, show_docs=False, data={'data': location_df_with_clusters})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from src.data.data_analysis import show_kepler_map\n",
    "\n",
    "print('Metr-LA speed clusters on the first Monday:')\n",
    "show_kepler_map(location_df_with_clusters, None)''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05f7e838c9ec4c22ab5e809b17fb83b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(data={'data':      sensor_id  latitude  longitude  cluster       speed  datetime\n",
       "0       773869  34.1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = m.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.expand_dims(np.repeat(np.linspace(0, 1, n_timesteps), n_nodes), axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.concatenate([np.repeat(np.linspace(0, 1, n_timesteps), n_nodes)] * n_nodes, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.repeat(adj_matrix, 12).reshape(speed_distance_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#speed_distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = np.zeros((n_total_nodes, n_total_nodes))\n",
    "\n",
    "for i in range(similarity_matrix.shape[0]):\n",
    "    for j in range(similarity_matrix.shape[1]):\n",
    "        i_timestep = i // n_nodes\n",
    "        j_timestep = j // n_nodes\n",
    "        \n",
    "        i_id = i % n_nodes\n",
    "        j_id = j % n_nodes\n",
    "        \n",
    "        time_difference = abs(i_timestep - j_timestep)\n",
    "        #speed_difference = np.linalg.norm(sample_reshaped[i] - sample_reshaped[j])\n",
    "        \n",
    "        if (adj_matrix[i_id][j_id] > .5) * (time_difference <= 2):\n",
    "            speed_difference = np.linalg.norm(sample_reshaped[i] - sample_reshaped[j])\n",
    "        else:\n",
    "            speed_difference = float('inf')\n",
    "        \n",
    "        similarity_matrix[i][j] = speed_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = np.max(similarity_matrix[similarity_matrix != float('inf')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix[similarity_matrix == float('inf')] = max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00000000e+00 3.14331055e-03 3.24172974e-02 4.27729034e+00\n",
      " 4.36017609e+00 4.36315918e+00 5.13887024e+00 5.16516113e+00\n",
      " 5.19464874e+00 8.32704544e+01]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(similarity_matrix[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.796418782568813"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "dbscan = DBSCAN(metric='precomputed', eps=10., min_samples=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = dbscan.fit_predict(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = np.expand_dims(clusters, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2484, 1)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = clusters.reshape(n_timesteps, n_nodes, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 207, 1)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ = np.concatenate((sample, clusters), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 207, 2)\n"
     ]
    }
   ],
   "source": [
    "print(sample_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict\n",
    "\n",
    "def get_node_values_with_location_dataframe(\n",
    "    node_values: np.ndarray, node_pos_dict: Dict[int, str],\n",
    "    locations_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Get a pandas dataframe from a pandas dataframe of node speed values\n",
    "    and a pandas dataframe of node locations. The resulting dataframe\n",
    "    has for each timestamp the value of the metric for each node and\n",
    "    the location of the node in the form of latitude and longitude.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    node_values : ndarray\n",
    "        The numpy array containing the values of the cluster and speed of\n",
    "        each node for each timestamp.\n",
    "    locations_df : DataFrame\n",
    "        The dataframe containing the location of each node.\n",
    "    metric_name : str\n",
    "        The name of the metric that will be used in the resulting dataframe.\n",
    "    turn_datetimes_to_timestamp : bool\n",
    "        Whether to turn the datetimes to timestamp or not.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        The resulting dataframe containing the values of the metric for\n",
    "        each node and the location of the node in the form of latitude\n",
    "        and longitude.\n",
    "    \"\"\"\n",
    "    nodes_information = []\n",
    "    \n",
    "    for time_idx, node_matrix in enumerate(node_values):\n",
    "        for node_idx, features in enumerate(node_matrix):\n",
    "            node_id = node_pos_dict[node_idx]\n",
    "\n",
    "            latitude = locations_df.loc[\n",
    "                locations_df['sensor_id'] == node_id].latitude.values[0]\n",
    "            longitude = locations_df.loc[\n",
    "                locations_df['sensor_id'] == node_id].longitude.values[0]\n",
    "    \n",
    "            nodes_information.append(\n",
    "                [node_id,\n",
    "                 latitude,\n",
    "                 longitude,\n",
    "                 features[1],\n",
    "                 features[0],\n",
    "                 time_idx])\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'sensor_id': [n[0] for n in nodes_information],\n",
    "        'latitude': [n[1] for n in nodes_information],\n",
    "        'longitude': [n[2] for n in nodes_information],\n",
    "        'cluster': [n[3] for n in nodes_information],\n",
    "        'speed': [n[4] for n in nodes_information],\n",
    "        'datetime': [n[5] for n in nodes_information]\n",
    "    })\n",
    "    df['cluster'] = df['cluster'].astype(int)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df_with_clusters = get_node_values_with_location_dataframe(\n",
    "    sample_, node_pos_dict, locations_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4, 13,  5,  6, 37,  7, 41,  8,  9, 10, 42, 43, 11,\n",
       "       44, 12, 14, 15, -1, 16, 45, 46, 17, 18, 47, 19, 20, 21, 48, 49, 50,\n",
       "       22, 23, 24, 25, 51, 52, 26, 27, 28, 29, 30, 53, 54, 31, 32, 38, 55,\n",
       "       33, 56, 57, 34, 58, 40, 35, 36, 59, 60, 39])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_df_with_clusters['cluster'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location_df_with_clusters['cluster'] = location_df_with_clusters['cluster'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sensor_id</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>cluster</th>\n",
       "      <th>speed</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>773869</td>\n",
       "      <td>34.15497</td>\n",
       "      <td>-118.31829</td>\n",
       "      <td>0</td>\n",
       "      <td>105.516815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>767541</td>\n",
       "      <td>34.11621</td>\n",
       "      <td>-118.23799</td>\n",
       "      <td>1</td>\n",
       "      <td>106.308350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>767542</td>\n",
       "      <td>34.11641</td>\n",
       "      <td>-118.23819</td>\n",
       "      <td>1</td>\n",
       "      <td>110.634773</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>717447</td>\n",
       "      <td>34.07248</td>\n",
       "      <td>-118.26772</td>\n",
       "      <td>2</td>\n",
       "      <td>81.586983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>717446</td>\n",
       "      <td>34.07142</td>\n",
       "      <td>-118.26572</td>\n",
       "      <td>3</td>\n",
       "      <td>44.713619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>717592</td>\n",
       "      <td>34.14604</td>\n",
       "      <td>-118.22430</td>\n",
       "      <td>0</td>\n",
       "      <td>100.792572</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>717595</td>\n",
       "      <td>34.14163</td>\n",
       "      <td>-118.18290</td>\n",
       "      <td>1</td>\n",
       "      <td>109.369804</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>772168</td>\n",
       "      <td>34.16542</td>\n",
       "      <td>-118.47985</td>\n",
       "      <td>39</td>\n",
       "      <td>95.773941</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>718141</td>\n",
       "      <td>34.15133</td>\n",
       "      <td>-118.37456</td>\n",
       "      <td>2</td>\n",
       "      <td>106.050285</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>769373</td>\n",
       "      <td>34.10262</td>\n",
       "      <td>-118.31747</td>\n",
       "      <td>2</td>\n",
       "      <td>82.925262</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2484 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sensor_id  latitude  longitude  cluster       speed  datetime\n",
       "0       773869  34.15497 -118.31829        0  105.516815         0\n",
       "1       767541  34.11621 -118.23799        1  106.308350         0\n",
       "2       767542  34.11641 -118.23819        1  110.634773         0\n",
       "3       717447  34.07248 -118.26772        2   81.586983         0\n",
       "4       717446  34.07142 -118.26572        3   44.713619         0\n",
       "...        ...       ...        ...      ...         ...       ...\n",
       "2479    717592  34.14604 -118.22430        0  100.792572        11\n",
       "2480    717595  34.14163 -118.18290        1  109.369804        11\n",
       "2481    772168  34.16542 -118.47985       39   95.773941        11\n",
       "2482    718141  34.15133 -118.37456        2  106.050285        11\n",
       "2483    769373  34.10262 -118.31747        2   82.925262        11\n",
       "\n",
       "[2484 rows x 6 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location_df_with_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keplergl.keplergl import KeplerGl\n",
    "\n",
    "m = KeplerGl(height=800, show_docs=False, data={'data': location_df_with_clusters})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from src.data.data_analysis import show_kepler_map\n",
    "\n",
    "print('Metr-LA speed clusters on the first Monday:')\n",
    "show_kepler_map(location_df_with_clusters, None)''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff6162bb0494db69e2f15a2c9778c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(data={'data':      sensor_id  latitude  longitude  cluster       speed  datetime\n",
       "0       773869  34.1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = m.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
