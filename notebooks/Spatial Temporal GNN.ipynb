{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for autoreloading\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/LMissher/STGNN/blob/main/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riccardo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Tuple\n",
    "\n",
    "class S_GNN(nn.Module):\n",
    "    def __init__(self, input_dim: int) -> None:\n",
    "        super().__init__()\n",
    "        # Module to obtain the latent representation of the input.\n",
    "        # TODO: check if the latent representation is ok\n",
    "        self.latent_encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.Linear(64, input_dim)\n",
    "        )\n",
    "        # Linear layer to model the spatial feature extraction.\n",
    "        self.linear = nn.Linear(input_dim, input_dim)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # TODO: Check if the input itself is an Adjacency Matrix, otherwise one must be provided as A\n",
    "        # Get the latent representation of the input.\n",
    "        p = self.latent_encoder(x)\n",
    "        \n",
    "        # The following are parameters, henc no gradient storing is required.\n",
    "        with torch.no_grad():\n",
    "            # Apply score function: Score(p1, p2) = p1^T p2.\n",
    "            score = p @ p.transpose(-1, -2)\n",
    "            # Pair-wise relation between any road node.\n",
    "            # TODO: Are the phi in the \n",
    "            R = torch.relu(score).exp() / torch.relu(score).exp().sum()\n",
    "            # TODO: A_hat should probably be provided by the model since it is just a refined adjacency matrix, unless we pass the adjacency matrix as an input\n",
    "            #A_hat = p + torch.eye(p.shape[0], p.shape[1], device=x.device)\n",
    "            # Get refined adjacency matrix: A_hat = A + I\n",
    "            A_hat = torch.rand(x.shape[0], x.shape[0], device=DEVICE) #R # TODO: CHANGE\n",
    "            # Get the sparsified relation matrix\n",
    "            R_hat = (A_hat > 0).float() * R + torch.eye(R.shape[0], R.shape[1], device=x.device) #torch.eye(p.shape[0], p.shape[1], device=x.device)\n",
    "            # Get refined degree matrix for R_hat\n",
    "            D_hat = R_hat.sum(-1)\n",
    "            D_hat = torch.diag_embed(D_hat)\n",
    "            # TODO: handle infinities and nones\n",
    "\n",
    "            A = (D_hat ** -.5) @ R_hat @ (D_hat ** -.5)\n",
    "            \n",
    "            #print(A, x)\n",
    "        return torch.relu(self.linear(A @ x))\n",
    "\n",
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size: Tuple[int, int], hidden_size: int = 64) -> None:\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        n_nodes, n_features = self.input_size\n",
    "        # Define a GRUCell layer for each node.\n",
    "        gru_list = [nn.GRUCell(n_features, hidden_size) for _ in range(n_nodes)]\n",
    "        self.gru_layers = nn.ModuleList(gru_list)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, x_h: torch.Tensor):\n",
    "        # Get number of nodes.\n",
    "        _, n_nodes, _ = x.shape\n",
    "        # Apply GRU layer on each node features.\n",
    "        outs = [self.gru_layers[i](x[:, i,:], x_h[:, i,:]) for i in range(n_nodes)]\n",
    "        # Stack the results by row.\n",
    "        #print('o', torch.stack(outs, 0))\n",
    "        return torch.stack(outs, 1)#.to(x.device)\n",
    "    \n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, n_features: int, n_heads: int = 4,\n",
    "                 hidden_dimension: int = 64) -> None:\n",
    "        super().__init__()\n",
    "        #_, n_features = input_size\n",
    "        # self.queries_linear = nn.Linear(n_features, n_features)\n",
    "        # self.keys_linear = nn.Linear(n_features, n_features)\n",
    "        # self.values_linear = nn.Linear(n_features, n_features)\n",
    "        self.multi_head_attention = nn.MultiheadAttention(n_features, n_heads)\n",
    "        self.normalization = nn.LayerNorm(n_features)\n",
    "        self.normalization_out = nn.LayerNorm(n_features)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(n_features, hidden_dimension),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dimension, n_features)\n",
    "        )\n",
    "        \n",
    "    #def _attention(Q, K, V):\n",
    "    #    d = K.shape[-1]\n",
    "    #    return torch.softmax(((Q @ K.transpose(1, 0)) / d ** .5) @ V)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # Get queries, keys and values.\n",
    "        #Q = x.clone() #self.queries_linear(x)\n",
    "        #K = x.clone() #self.keys_linear(x)\n",
    "        #V = x.clone() #self.values_linear(x)\n",
    "        \n",
    "        # Multi head attention mechanism.\n",
    "        out, _ = self.multi_head_attention(x, x, x)\n",
    "        \n",
    "        # Apply residual connection and batch normalization.\n",
    "        out += x\n",
    "        norm = self.normalization(out)\n",
    "        \n",
    "        # Apply feed forward module.\n",
    "        out = self.feed_forward(norm)\n",
    "        \n",
    "        # Apply residual connection and batch normalization.\n",
    "        out += norm\n",
    "        return self.normalization_out(out)\n",
    "    \n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, n_features: int, max_len: int = 5000) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, n_features, 2) * (-math.log(10000.0) / n_features))\n",
    "        pe = torch.zeros(max_len, 1, n_features)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x + self.pe[:x.size(0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatioTemporalGNN(nn.Module):\n",
    "    def __init__(self, n_nodes, n_features, len_timeseries, hidden_dimension = 64, output_graphs = 4):\n",
    "        super().__init__()\n",
    "        # self.start_emb = nn.Linear(infea, outfea)\n",
    "        # self.end_emb = nn.Linear(outfea, infea)\n",
    "        self.s_gnns = nn.ModuleList([S_GNN((n_features)) for _ in range(len_timeseries)])\n",
    "        self.hidden_s_gnns = nn.ModuleList([S_GNN((hidden_dimension)) for _ in range(len_timeseries -1)])\n",
    "        self.grus = nn.ModuleList([GRU((n_nodes, n_features), hidden_dimension) for _ in range(len_timeseries)])\n",
    "        self.positional_encoding = PositionalEncoding(hidden_dimension)\n",
    "        self.transformers = nn.ModuleList([Transformer(hidden_dimension, hidden_dimension=hidden_dimension) for _ in range(len_timeseries)])\n",
    "        \n",
    "        self.prediction_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_dimension, n_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_features, n_features)\n",
    "            #nn.Upsample(size=(1, output_graphs, n_nodes, n_features))\n",
    "        )\n",
    "\n",
    "        self.len_timeseries = len_timeseries\n",
    "        self.hidden_dimension = hidden_dimension\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = x.unsqueeze(-1)\n",
    "        # x = self.start_emb(x)\n",
    "        sgnn_outs = []\n",
    "        for i in range(self.len_timeseries):\n",
    "            x_ = self.s_gnns[i](x[:, i])\n",
    "            if i > 0:\n",
    "                hidden_state = sgnn_outs[i-1] \n",
    "            else:\n",
    "                batch_size, _, n_nodes, _ = x.shape\n",
    "                hidden_state = torch.zeros(\n",
    "                    (batch_size, n_nodes, self.hidden_dimension),\n",
    "                    device=DEVICE)\n",
    "            x_ = self.grus[i](x_, hidden_state)\n",
    "            sgnn_outs.append(x_)\n",
    "            if i < self.len_timeseries:\n",
    "                self.hidden_s_gnns[i-1](x_)\n",
    "                \n",
    "        #x = self.positional_encoding(x)\n",
    "        \n",
    "        # TODO: stack row-wise and pass to the transformer\n",
    "        out = torch.stack(sgnn_outs, 1)\n",
    "        out = self.positional_encoding(out)\n",
    "        # TODO: The weights of the transformer seem to be shared, pass just subsets of nodes to a single layer.\n",
    "        transformer_outs = []\n",
    "        for i in range(self.len_timeseries):\n",
    "            transformer_outs.append(self.transformers[i](out[:, i]))\n",
    "        out = torch.stack(transformer_outs, 1)\n",
    "        \n",
    "        return self.prediction_layer(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 2, 4])\n",
      "tensor([[[[nan, nan, nan, nan],\n",
      "          [nan, nan, nan, nan]],\n",
      "\n",
      "         [[nan, nan, nan, nan],\n",
      "          [nan, nan, nan, nan]]]], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "s = SpatioTemporalGNN(2, 4, 2).to(DEVICE)\n",
    "a = torch.tensor([\n",
    "    [[[12., -1, 4.4, 5.5],\n",
    "      [5., 3., 4, -2]],\n",
    "     [[12., -1, 4.4, 5.5],\n",
    "      [5., 3., 4, -2]]]], device=DEVICE)\n",
    "print(a.shape)\n",
    "d = s(a)\n",
    "\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.9849,  2.0399,  1.5521,  0.3263],\n",
      "         [-1.3656,  3.0266, -0.5121,  1.8576]],\n",
      "\n",
      "        [[-0.9849,  2.0399,  1.5521,  0.3263],\n",
      "         [-1.3656,  3.0266, -0.5121,  1.8576]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n",
      "tensor([[[inf, inf],\n",
      "         [inf, inf]],\n",
      "\n",
      "        [[inf, inf],\n",
      "         [inf, inf]]], device='cuda:0') tensor([[[12.0000, -1.0000,  4.4000,  5.5000],\n",
      "         [ 5.0000,  3.0000,  4.0000, -2.0000]],\n",
      "\n",
      "        [[12.0000, -1.0000,  4.4000,  5.5000],\n",
      "         [ 5.0000,  3.0000,  4.0000, -2.0000]]], device='cuda:0')\n",
      "tensor([[[nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan]],\n",
      "\n",
      "        [[nan, nan, nan, nan],\n",
      "         [nan, nan, nan, nan]]], device='cuda:0', grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "s = S_GNN(4).to(DEVICE)\n",
    "a = torch.tensor([[[12., -1, 4.4, 5.5],\n",
    "                  [5., 3., 4, -2]],\n",
    "                  [[12., -1, 4.4, 5.5],\n",
    "                  [5., 3., 4, -2]]\n",
    "                  ], device=DEVICE)\n",
    "#print(a)\n",
    "d = s(a)\n",
    "\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[12.0000, -1.0000,  4.4000,  5.5000],\n",
      "         [ 5.0000,  3.0000,  4.0000, -2.0000]],\n",
      "\n",
      "        [[12.0000, -1.0000,  4.4000,  5.5000],\n",
      "         [ 5.0000,  3.0000,  4.0000, -2.0000]]], device='cuda:0')\n",
      "tensor([[[ 1.3005,  0.8127,  0.7641, -0.4614,  1.8968,  2.1198, -0.3613,\n",
      "           1.6788,  0.6115,  0.9929, -0.0058,  1.6665,  0.3433, -0.1648,\n",
      "          -0.1502,  0.6703,  0.1902,  1.1755, -0.0786,  0.5219,  1.8726,\n",
      "           0.9069,  0.9686, -0.3306, -0.4870, -0.8275,  1.3886,  0.1678,\n",
      "          -0.3717,  0.6982,  0.2038, -1.8341,  2.6371, -1.3918,  2.6478,\n",
      "           0.2898,  2.8102, -0.1003,  1.8418,  0.2130, -0.0728, -1.5794,\n",
      "           0.3305, -0.9606,  1.3234, -0.7743,  1.5515,  0.7421,  0.9246,\n",
      "           1.2294,  0.3247,  2.3740, -0.4397, -0.1896,  1.5115,  0.4113,\n",
      "          -0.9112,  0.1225, -1.7437,  0.3361, -0.1516,  0.3274, -0.1993,\n",
      "          -0.8112],\n",
      "         [-0.2053, -0.2915,  0.6704, -1.0087,  1.5262,  1.9237,  2.6816,\n",
      "           1.7600, -0.4572, -0.7719, -1.2873, -0.6162, -0.0139,  1.5390,\n",
      "           0.3491,  0.9790, -0.4218,  1.4642,  0.1265, -0.4590, -0.2633,\n",
      "           1.2147, -0.3798, -0.5428, -0.9054, -1.3090,  0.0046,  0.6116,\n",
      "           1.3900,  0.0235,  0.7618,  0.2030, -0.6312,  1.6897,  0.9645,\n",
      "           1.0270,  0.4492,  1.9827,  0.0927, -0.0742,  0.3254,  0.5688,\n",
      "           1.0392, -0.4420, -0.9949,  1.1884, -0.0234,  1.3883,  0.7033,\n",
      "          -0.4692,  1.5225, -0.0816,  0.8773,  0.6870, -1.0243,  0.8131,\n",
      "           1.8162,  0.9433, -0.5674,  0.7195, -0.0790,  0.6782,  0.7321,\n",
      "          -0.1133]],\n",
      "\n",
      "        [[ 0.2359, -0.6727,  2.6233, -0.3691,  0.9792, -0.2670, -0.4974,\n",
      "           0.2312, -0.0447,  0.0742,  1.6175, -0.8798, -0.6483,  0.1414,\n",
      "           0.0297, -1.2317, -0.4169,  0.9232, -1.3214, -0.1807, -0.0392,\n",
      "           1.7511,  1.5417,  0.4908,  0.5544,  0.8978,  0.5967,  0.7010,\n",
      "           0.6232,  0.7656,  0.7313,  0.9109,  0.8908,  2.8046, -0.5990,\n",
      "           0.4108, -1.8446, -0.5338,  1.4383,  0.7182, -0.1876,  0.2407,\n",
      "          -0.8366, -0.9483,  0.2217, -1.1789,  2.6331,  0.6584, -1.2814,\n",
      "          -0.2658, -0.8346,  0.1405, -0.7183, -0.0966,  0.6016, -1.7159,\n",
      "           0.9337,  0.7833, -0.9162,  0.6900,  2.3955,  0.9153,  2.6215,\n",
      "           0.9748],\n",
      "         [-0.4695, -0.6682, -1.1898, -1.1452,  0.1871,  0.7780, -0.7610,\n",
      "          -0.5804, -1.0421,  0.1642, -0.2477,  0.2154,  0.9074, -1.2961,\n",
      "           1.4682,  0.5718,  1.6796,  0.9523,  1.5161,  0.4441,  1.9147,\n",
      "          -0.7990, -0.3101, -1.4981,  0.5469,  0.5267, -0.9684,  1.0863,\n",
      "           0.7162,  0.1487, -0.0554,  0.9165,  1.7514,  1.2804,  1.2187,\n",
      "           2.2668,  0.7247, -1.6744,  2.6246,  0.8748, -1.4034, -1.7223,\n",
      "           1.3711,  0.0679,  0.6772, -0.9653,  1.1239, -0.5273, -0.3720,\n",
      "          -1.3327,  0.3428, -0.5745, -0.7101, -1.2685,  0.2213,  0.8245,\n",
      "           0.2966,  0.9741,  0.6837,  0.8997, -0.2505,  0.0780, -0.0773,\n",
      "          -1.7762]]], device='cuda:0', grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "s = GRU((2, 4)).to(DEVICE)\n",
    "a = torch.tensor([[[12., -1, 4.4, 5.5],\n",
    "                  [5., 3., 4, -2]],\n",
    "                  [[12., -1, 4.4, 5.5],\n",
    "                  [5., 3., 4, -2]]], device=DEVICE)\n",
    "b = torch.randint(-2, 4, (2, 2, 64), dtype=torch.float32, device=DEVICE)  #tensor([[7., 1.3, -2, 4], [0., 3., -5, 1]], device=DEVICE)\n",
    "print(a)\n",
    "d = s(a, b)\n",
    "\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[12.0000, -1.0000,  4.4000,  5.5000],\n",
      "         [ 5.0000,  3.0000,  4.0000, -2.0000]],\n",
      "\n",
      "        [[12.0000, -1.0000,  4.4000,  5.5000],\n",
      "         [ 5.0000,  3.0000,  4.0000, -2.0000]]], device='cuda:0')\n",
      "tensor([[[ 0.8325, -0.8137,  1.1405, -1.1593],\n",
      "         [ 0.3592,  0.3865,  0.9393, -1.6850]],\n",
      "\n",
      "        [[ 0.8325, -0.8137,  1.1405, -1.1593],\n",
      "         [ 0.3592,  0.3865,  0.9393, -1.6850]]], device='cuda:0',\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "s = Transformer(input_size=(2,4), n_heads = 4, hidden_dimension = 64).to(DEVICE)\n",
    "a = torch.tensor([[[12., -1, 4.4, 5.5],\n",
    "                  [5., 3., 4, -2]],\n",
    "                  [[12., -1, 4.4, 5.5],\n",
    "                  [5., 3., 4, -2]]], device=DEVICE)\n",
    "print(a)\n",
    "d = s(a)\n",
    "\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[12.0000,  0.0000,  4.4000,  6.5000],\n",
      "         [ 5.0000,  4.0000,  4.0000, -1.0000]],\n",
      "\n",
      "        [[12.8415, -0.4597,  4.4100,  6.4999],\n",
      "         [ 5.8415,  3.5403,  4.0100, -1.0001]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "s = PositionalEncoding(4).to(DEVICE)\n",
    "a = torch.tensor([[[12., -1, 4.4, 5.5],\n",
    "                  [5., 3., 4, -2]],\n",
    "                  [[12., -1, 4.4, 5.5],\n",
    "                  [5., 3., 4, -2]]\n",
    "                  ], device=DEVICE)\n",
    "#print(a)\n",
    "d = s(a)\n",
    "\n",
    "print(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bb5e395f71e970ef2dfa88b10e29155c2f154fbffe5a547ccb4cc942724aa68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
