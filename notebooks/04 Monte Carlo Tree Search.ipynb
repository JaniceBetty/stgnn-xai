{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Set the main path in the root folder of the project.\n",
    "sys.path.append(os.path.join('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Settings for autoreloading.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.seed import set_random_seed\n",
    "\n",
    "# Set the random seed for deterministic operations.\n",
    "SEED = 42\n",
    "set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected device is: \"cuda\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set the device for training and querying the model.\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'The selected device is: \"{DEVICE}\"')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_DATA_DIR = os.path.join('..', 'data', 'metr-la')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(os.path.join(BASE_DATA_DIR, 'processed', 'scaler.pkl'), 'rb') as f:\n",
    "    scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riccardo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "from src.spatial_temporal_gnn.model import SpatialTemporalGNN\n",
    "from src.explanation.navigator.model import Navigator\n",
    "from src.data.data_extraction import get_adjacency_matrix\n",
    "\n",
    "# Get the adjacency matrix\n",
    "adj_matrix_structure = get_adjacency_matrix(\n",
    "    os.path.join(BASE_DATA_DIR, 'raw', 'adj_mx_metr_la.pkl'))\n",
    "\n",
    "# Get the header of the adjacency matrix, the node indices and the\n",
    "# matrix itself.\n",
    "header, node_ids_dict, adj_matrix = adj_matrix_structure\n",
    "\n",
    "# Get the STGNN and load the checkpoints.\n",
    "spatial_temporal_gnn = SpatialTemporalGNN(9, 1, 12, 12, adj_matrix, DEVICE, 64)\n",
    "\n",
    "stgnn_checkpoints_path = os.path.join('..', 'models', 'checkpoints',\n",
    "                                      'st_gnn_metr_la.pth')\n",
    "\n",
    "stgnn_checkpoints = torch.load(stgnn_checkpoints_path)\n",
    "spatial_temporal_gnn.load_state_dict(stgnn_checkpoints['model_state_dict'])\n",
    "\n",
    "# Set the STGNN in evaluation mode.\n",
    "spatial_temporal_gnn.eval();\n",
    "\n",
    "# Get the Navigator and load the checkpoints.\n",
    "navigator = Navigator(DEVICE)\n",
    "\n",
    "navigator_checkpoints_path = os.path.join('..', 'models', 'checkpoints',\n",
    "                                          'navigator_metr_la.pth')\n",
    "\n",
    "navigator_checkpoints = torch.load(navigator_checkpoints_path)\n",
    "navigator.load_state_dict(navigator_checkpoints['model_state_dict'])\n",
    "\n",
    "# Set the Navigator in evaluation mode.\n",
    "navigator.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Get the data scaler.\n",
    "with open(os.path.join(BASE_DATA_DIR, 'processed', 'scaler.pkl'), 'rb') as f:\n",
    "    scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Get the data and the values predicted by the STGNN.\n",
    "x_train = np.load(os.path.join(BASE_DATA_DIR, 'explainable', 'x_train.npy'))\n",
    "y_train = np.load(os.path.join(BASE_DATA_DIR, 'explainable', 'y_train.npy'))\n",
    "x_val = np.load(os.path.join(BASE_DATA_DIR, 'explainable', 'x_val.npy'))\n",
    "y_val = np.load(os.path.join(BASE_DATA_DIR, 'explainable', 'y_val.npy'))\n",
    "x_test = np.load(os.path.join(BASE_DATA_DIR, 'explainable', 'x_test.npy'))\n",
    "y_test = np.load(os.path.join(BASE_DATA_DIR, 'explainable', 'y_test.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample, y_sample = x_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_size = min((y_sample.flatten() != 0).sum() * 2, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "print(explanation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution 1/50\n",
      "mae: 9.096492767333984\n",
      "Execution 2/50\n",
      "mae: 9.091655731201172\n",
      "Execution 3/50\n",
      "mae: 9.091655731201172\n",
      "Execution 4/50\n",
      "mae: 9.091655731201172\n",
      "Execution 5/50\n",
      "mae: 9.091655731201172\n",
      "Execution 6/50\n",
      "mae: 9.091655731201172\n",
      "Execution 7/50\n",
      "mae: 9.091655731201172\n",
      "Execution 8/50\n",
      "mae: 9.091655731201172\n",
      "Execution 9/50\n",
      "mae: 9.091655731201172\n",
      "Execution 10/50\n",
      "mae: 9.091655731201172\n",
      "Execution 11/50\n",
      "mae: 9.091655731201172\n",
      "Execution 12/50\n",
      "mae: 9.091655731201172\n",
      "Execution 13/50\n",
      "mae: 9.091655731201172\n",
      "Execution 14/50\n",
      "mae: 9.091655731201172\n",
      "Execution 15/50\n",
      "mae: 9.091655731201172\n",
      "Execution 16/50\n",
      "mae: 9.091655731201172\n",
      "Execution 17/50\n",
      "mae: 9.091655731201172\n",
      "Execution 18/50\n",
      "mae: 9.091655731201172\n",
      "Execution 19/50\n",
      "mae: 9.091655731201172\n",
      "Execution 20/50\n",
      "mae: 9.091655731201172\n",
      "Execution 21/50\n",
      "mae: 9.091655731201172\n",
      "Execution 22/50\n",
      "mae: 9.091655731201172\n",
      "Execution 23/50\n",
      "mae: 9.091655731201172\n",
      "Execution 24/50\n",
      "mae: 9.091655731201172\n",
      "Execution 25/50\n",
      "mae: 9.091655731201172\n",
      "Execution 26/50\n",
      "mae: 9.091655731201172\n",
      "Execution 27/50\n",
      "mae: 9.091655731201172\n",
      "Execution 28/50\n",
      "mae: 9.091655731201172\n",
      "Execution 29/50\n",
      "mae: 9.091655731201172\n",
      "Execution 30/50\n",
      "mae: 9.091655731201172\n",
      "Execution 31/50\n",
      "mae: 9.091655731201172\n",
      "Execution 32/50\n",
      "mae: 9.091655731201172\n",
      "Execution 33/50\n",
      "mae: 9.091655731201172\n",
      "Execution 34/50\n",
      "mae: 9.091655731201172\n",
      "Execution 35/50\n",
      "mae: 9.091655731201172\n",
      "Execution 36/50\n",
      "mae: 9.091655731201172\n",
      "Execution 37/50\n",
      "mae: 9.091655731201172\n",
      "Execution 38/50\n",
      "mae: 9.091655731201172\n",
      "Execution 39/50\n",
      "mae: 9.091655731201172\n",
      "Execution 40/50\n",
      "mae: 9.091655731201172\n",
      "Execution 41/50\n",
      "mae: 9.091655731201172\n",
      "Execution 42/50\n",
      "mae: 9.091655731201172\n",
      "Execution 43/50\n",
      "mae: 9.091655731201172\n",
      "Execution 44/50\n",
      "mae: 9.091655731201172\n",
      "Execution 45/50\n",
      "mae: 9.091655731201172\n",
      "Execution 46/50\n",
      "mae: 9.091655731201172\n",
      "Execution 47/50\n",
      "mae: 9.091655731201172\n",
      "Execution 48/50\n",
      "mae: 9.091655731201172\n",
      "Execution 49/50\n",
      "mae: 9.091655731201172\n",
      "Execution 50/50\n",
      "mae: 9.091655731201172\n"
     ]
    }
   ],
   "source": [
    "from src.explanation.monte_carlo.search import get_best_input_subset\n",
    "\n",
    "subset = get_best_input_subset(\n",
    "    x_sample,\n",
    "    y_sample,\n",
    "    adj_matrix,\n",
    "    spatial_temporal_gnn,\n",
    "    navigator,\n",
    "    scaler,\n",
    "    verbose=True,\n",
    "    maximum_leaf_size=explanation_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10, 3, 61.111111111111114, 0.03474635163307853, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (11, 62, 34.5, 0.03822098679638638, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (9, 3, 58.125, 0.03127171646977067, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (10, 62, 31.555555555555557, 0.03474635163307853, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (11, 18, 54.125, 0.03822098679638638, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (10, 14, 54.111111111111114, 0.03474635163307853, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (11, 22, 52.125, 0.03822098679638638, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (11, 9, 58.25, 0.03822098679638638, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (11, 0, 62.25, 0.03822098679638638, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (11, 14, 55.25, 0.03822098679638638, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (11, 3, 60.0, 0.03822098679638638, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (10, 21, 49.55555555555556, 0.03474635163307853, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (5, 18, 41.333333333333336, 0.017373175816539264, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (2, 18, 35.625, 0.006949270326615705, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (8, 21, 45.375, 0.02779708130646282, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (9, 8, 53.25, 0.03127171646977067, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (9, 21, 46.75, 0.03127171646977067, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (10, 18, 48.0, 0.03474635163307853, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (7, 18, 42.0, 0.024322446143154968, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (11, 8, 52.625, 0.03822098679638638, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (9, 18, 44.0, 0.03127171646977067, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (11, 21, 43.75, 0.03822098679638638, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (10, 8, 47.0, 0.03474635163307853, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0), (8, 18, 30.375, 0.02779708130646282, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "print(subset.input_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
