{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Set the main path in the root folder of the project.\n",
    "sys.path.append(os.path.join('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for autoreloading.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.seed import set_random_seed\n",
    "\n",
    "# Set the random seed for deterministic operations.\n",
    "SEED = 42\n",
    "set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected device is: \"cuda\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set the device for training and querying the model.\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'The selected device is: \"{DEVICE}\"')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_DATA_DIR = os.path.join('..', 'data', 'pems-bay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(os.path.join(BASE_DATA_DIR, 'processed', 'scaler.pkl'), 'rb') as f:\n",
    "    scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.spatial_temporal_gnn.model import SpatialTemporalGNN\n",
    "from src.data.data_extraction import get_adjacency_matrix\n",
    "\n",
    "# Get the adjacency matrix\n",
    "adj_matrix_structure = get_adjacency_matrix(\n",
    "    os.path.join(BASE_DATA_DIR, 'raw', 'adj_mx_pems_bay.pkl'))\n",
    "\n",
    "# Get the header of the adjacency matrix, the node indices and the\n",
    "# matrix itself.\n",
    "header, node_ids_dict, adj_matrix = adj_matrix_structure\n",
    "\n",
    "# Get the STGNN and load the checkpoints.\n",
    "spatial_temporal_gnn = SpatialTemporalGNN(9, 1, 12, 12, adj_matrix, DEVICE, 64)\n",
    "\n",
    "stgnn_checkpoints_path = os.path.join('..', 'models', 'checkpoints',\n",
    "                                      'st_gnn_pems_bay.pth')\n",
    "\n",
    "stgnn_checkpoints = torch.load(stgnn_checkpoints_path)\n",
    "spatial_temporal_gnn.load_state_dict(stgnn_checkpoints['model_state_dict'])\n",
    "\n",
    "# Set the model in evaluation mode.\n",
    "spatial_temporal_gnn.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.data_extraction import get_locations_dataframe\n",
    "\n",
    "# Get the dataframe containing the latitude and longitude of each sensor.\n",
    "locations_df = get_locations_dataframe(\n",
    "    os.path.join(BASE_DATA_DIR, 'raw', 'graph_sensor_locations_pems_bay.csv'),\n",
    "    has_header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the node positions dictionary.\n",
    "node_pos_dict = { i: id for id, i in node_ids_dict.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from src.spatial_temporal_gnn.prediction import predict\n",
    "\n",
    "# Get the data and the values predicted by the STGNN.\n",
    "x_train = np.load(os.path.join(BASE_DATA_DIR, 'explained', 'x_train.npy'))[..., :1]\n",
    "x_val = np.load(os.path.join(BASE_DATA_DIR, 'explained', 'x_val.npy'))[..., :1]\n",
    "x_test = np.load(os.path.join(BASE_DATA_DIR, 'explained', 'x_test.npy'))[..., :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.config import MPH_TO_KMH_FACTOR\n",
    "\n",
    "# Turn the dataset in kilometers per hour.\n",
    "x_train = x_train * MPH_TO_KMH_FACTOR\n",
    "x_val = x_val * MPH_TO_KMH_FACTOR\n",
    "x_test = x_test * MPH_TO_KMH_FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, n_timesteps, n_nodes, _ = x_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjacency Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.explanation.clustering.clustering import (\n",
    "    get_adjacency_distance_matrix)\n",
    "\n",
    "adj_distance_matrix = get_adjacency_distance_matrix(adj_matrix, n_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Adjacency Distance Matrix: (2484, 2484)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of the Adjacency Distance Matrix: {adj_distance_matrix.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Distance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.explanation.clustering.clustering import (\n",
    "    get_temporal_distance_matrix)\n",
    "\n",
    "temporal_distance_matrix = get_temporal_distance_matrix(n_nodes, n_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Temporal Distance Matrix: (2484, 2484)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the Temporal Distance Matrix:',\n",
    "      f'{temporal_distance_matrix.shape}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: n_clusters: 3 speed_distance_weight: 2\n",
      "[99/99] - 381s - Within Cluster Variance: 3.12 - Connected Clusters Dissimilarity: 15.5 - Average time: 3.84s              \n",
      "Testing: n_clusters: 3 speed_distance_weight: 3\n",
      "[99/99] - 363s - Within Cluster Variance: 2.8 - Connected Clusters Dissimilarity: 16.3 - Average time: 3.67s               \n",
      "Testing: n_clusters: 4 speed_distance_weight: 2\n",
      "[99/99] - 522s - Within Cluster Variance: 2.38 - Connected Clusters Dissimilarity: 17 - Average time: 5.27s                \n",
      "Testing: n_clusters: 4 speed_distance_weight: 3\n",
      "[99/99] - 521s - Within Cluster Variance: 2.44 - Connected Clusters Dissimilarity: 17.6 - Average time: 5.27s              \n",
      "Testing: n_clusters: 5 speed_distance_weight: 2\n",
      "[99/99] - 650s - Within Cluster Variance: 1.84 - Connected Clusters Dissimilarity: 17.9 - Average time: 6.57s              \n",
      "Testing: n_clusters: 5 speed_distance_weight: 3\n",
      "[99/99] - 556s - Within Cluster Variance: 1.9 - Connected Clusters Dissimilarity: 17.7 - Average time: 5.62s               \n"
     ]
    }
   ],
   "source": [
    "from src.explanation.clustering.evaluation import (\n",
    "    apply_grid_search_on_explanation_dataset)\n",
    "\n",
    "# Apply the grid search on a subset of the training set.\n",
    "apply_grid_search_on_explanation_dataset(\n",
    "    x=x_train[::10],\n",
    "    adj_distance_matrix=adj_distance_matrix,\n",
    "    temporal_distance_matrix=temporal_distance_matrix,\n",
    "    speed_distance_weight_list=[2, 3],\n",
    "    n_clusters_list=[3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the best parameters based on the results of the grid search.\n",
    "\n",
    "SPEED_DISTANCE_WEIGHT = 2\n",
    "N_CLUSTERS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[755/995] - 4573s - Within Cluster Variance: 2.01 - Connected Clusters Dissimilarity: 18.9 - Average time: 6.06s              \r"
     ]
    }
   ],
   "source": [
    "from src.explanation.clustering.evaluation import (\n",
    "    get_explanation_dataset_clustering_scores)\n",
    "\n",
    "get_explanation_dataset_clustering_scores(\n",
    "    x_train,\n",
    "    adj_distance_matrix=adj_distance_matrix,\n",
    "    temporal_distance_matrix=temporal_distance_matrix,\n",
    "    speed_distance_weight=SPEED_DISTANCE_WEIGHT,\n",
    "    n_clusters=N_CLUSTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Within Cluster Variance: 0.0421 Sample Connected Cluster Dissimilarity: 18 Sample Noise Ratio: 0.00966\n"
     ]
    }
   ],
   "source": [
    "from src.explanation.clustering.evaluation import (\n",
    "    get_explanation_dataset_clustering_scores)\n",
    "\n",
    "get_explanation_dataset_clustering_scores(\n",
    "    x_val,\n",
    "    adj_distance_matrix=adj_distance_matrix,\n",
    "    temporal_distance_matrix=temporal_distance_matrix,\n",
    "    speed_distance_weight=SPEED_DISTANCE_WEIGHT,\n",
    "    n_clusters=N_CLUSTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.explanation.clustering.evaluation import (\n",
    "    get_explanation_dataset_clustering_scores)\n",
    "\n",
    "get_explanation_dataset_clustering_scores(\n",
    "    x_test,\n",
    "    adj_distance_matrix=adj_distance_matrix,\n",
    "    temporal_distance_matrix=temporal_distance_matrix,\n",
    "    speed_distance_weight=SPEED_DISTANCE_WEIGHT,\n",
    "    n_clusters=N_CLUSTERS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
