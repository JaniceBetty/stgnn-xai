{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Set the main path in the root folder of the project.\n",
    "sys.path.append(os.path.join('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for autoreloading.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.seed import set_random_seed\n",
    "\n",
    "# Set the random seed for deterministic operations.\n",
    "SEED = 42\n",
    "set_random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected device is: \"cuda\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set the device for training and querying the model.\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'The selected device is: \"{DEVICE}\"')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "BASE_DATA_DIR = os.path.join('..', 'data', 'metr-la')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(os.path.join(BASE_DATA_DIR, 'processed', 'scaler.pkl'), 'rb') as f:\n",
    "    scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riccardo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "from src.spatial_temporal_gnn.model import SpatialTemporalGNN\n",
    "from src.explanation.navigator.model import Navigator\n",
    "from src.data.data_extraction import get_adjacency_matrix\n",
    "\n",
    "# Get the adjacency matrix\n",
    "adj_matrix_structure = get_adjacency_matrix(\n",
    "    os.path.join(BASE_DATA_DIR,'raw', 'adj_mx_metr_la.pkl'))\n",
    "\n",
    "# Get the header of the adjacency matrix, the node indices and the\n",
    "# matrix itself.\n",
    "header, node_ids_dict, adj_matrix = adj_matrix_structure\n",
    "\n",
    "# Get the STGNN and load the checkpoints.\n",
    "spatial_temporal_gnn = SpatialTemporalGNN(9, 1, 12, 12, adj_matrix, DEVICE, 64)\n",
    "\n",
    "stgnn_checkpoints_path = os.path.join('..', 'models', 'checkpoints',\n",
    "                                      'st_gnn_metr_la.pth')\n",
    "\n",
    "stgnn_checkpoints = torch.load(stgnn_checkpoints_path)\n",
    "spatial_temporal_gnn.load_state_dict(stgnn_checkpoints['model_state_dict'])\n",
    "\n",
    "# Set the STGNN in evaluation mode.\n",
    "spatial_temporal_gnn.eval();\n",
    "\n",
    "# Get the Navigator and load the checkpoints.\n",
    "navigator = Navigator(DEVICE)\n",
    "\n",
    "navigator_checkpoints_path = os.path.join('..', 'models', 'checkpoints',\n",
    "                                          'navigator_metr_la.pth')\n",
    "\n",
    "navigator_checkpoints = torch.load(navigator_checkpoints_path)\n",
    "navigator.load_state_dict(navigator_checkpoints['model_state_dict'])\n",
    "\n",
    "# Set the Navigator in evaluation mode.\n",
    "navigator.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Get the data scaler.\n",
    "with open(os.path.join(BASE_DATA_DIR, 'processed', 'scaler.pkl'), 'rb') as f:\n",
    "    scaler = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Get the data and the values predicted by the STGNN.\n",
    "x_train = np.load(os.path.join(BASE_DATA_DIR, 'explainable', 'x_train.npy'))\n",
    "y_train = np.load(os.path.join(BASE_DATA_DIR, 'explainable', 'y_train.npy'))\n",
    "x_val = np.load(os.path.join(BASE_DATA_DIR, 'explainable', 'x_val.npy'))\n",
    "y_val = np.load(os.path.join(BASE_DATA_DIR, 'explainable', 'y_val.npy'))\n",
    "x_test = np.load(os.path.join(BASE_DATA_DIR, 'explainable', 'x_test.npy'))\n",
    "y_test = np.load(os.path.join(BASE_DATA_DIR, 'explainable', 'y_test.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.43750000e+01, 1.00000000e+00, 6.76250000e+01, ...,\n",
       "       5.94285714e+01, 3.82209868e-02, 1.00000000e+00])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][x_train[0] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([69.166954, 68.800095, 69.31903 , 70.10495 , 69.646835, 70.45398 ,\n",
       "       69.90516 , 70.29881 , 70.60335 , 71.06508 , 70.954185, 69.60902 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0][y_train[0] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRY COMPUTING THE INPUT EVENT SCORES BEFORE BEFORE GOING THROUGH THE MCTS\n",
    "### ALGORITHM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from typing import List, Tuple\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "from src.spatial_temporal_gnn.metrics import MAE\n",
    "from src.spatial_temporal_gnn.model import SpatialTemporalGNN\n",
    "from src.explanation.navigator.model import Navigator\n",
    "from src.explanation.events import (\n",
    "    remove_features_by_events, get_largest_event_set)\n",
    "\n",
    "\n",
    "class Node():\n",
    "    \"\"\"\n",
    "    A representation of a single state.\n",
    "    MCTS works by constructing a tree of these Nodes.\n",
    "    Could be e.g. a chess or checkers board state.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, input_events: List[List[int]]) -> None:\n",
    "        self.input_events = input_events\n",
    "\n",
    "    def find_children(self) -> List[List[int]]:\n",
    "        \"\"\"\n",
    "        Get all possible successors of the current node.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        set of Node\n",
    "            All possible successors of the current node.\n",
    "        \"\"\"\n",
    "        children = []\n",
    "\n",
    "        for i, _ in enumerate(self.input_events):\n",
    "            input_events_subset = self.input_events[:i] + self.input_events[i+1:]\n",
    "            children.append(Node([ e for e in input_events_subset ]))\n",
    "\n",
    "        return children\n",
    "\n",
    "    def is_terminal(self, leaf_size: int) -> bool:\n",
    "        \"\"\"\n",
    "        Returns True if the node has less than or equal to `leaf_size`\n",
    "        events.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        leaf_size : int\n",
    "            The maximum number of events allowed in a leaf node.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            Whether or not the node is terminal.\n",
    "        \"\"\"\n",
    "        return len(self.input_events) <= leaf_size\n",
    "\n",
    "    def reward(\n",
    "        self, spatial_temporal_gnn: SpatialTemporalGNN,\n",
    "        x: torch.FloatTensor, y: torch.FloatTensor) -> float:\n",
    "        \"\"\"Get the reward of the current node in terms of the negative\n",
    "        Mean Absolute Error (MAE) between the predicted output data,\n",
    "        given the subset of input events expressed by the current node,\n",
    "        and the actual output data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        spatial_temporal_gnn : SpatialTemporalGNN\n",
    "            The Spatial Temporal GNN model used to predict the output\n",
    "            events.\n",
    "        x : FloatTensor\n",
    "            The input data.\n",
    "        y : FloatTensor\n",
    "            The output data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            The negative MAE between the predicted output data and the\n",
    "            actual output data.\n",
    "        \"\"\"\n",
    "        x = x.clone()\n",
    "        # Set the MAE criterion.\n",
    "        mae_criterion = MAE()\n",
    "        # Get the device of the spatial temporal GNN.\n",
    "        device = spatial_temporal_gnn.device\n",
    "\n",
    "        # Set the input events as a list.\n",
    "        input_events = [[0, e[0], e[1]] for e in self.input_events]\n",
    "        # Remove the features corresponding to the input events in\n",
    "        # the input data.\n",
    "        x_subset = remove_features_by_events(x, input_events)\n",
    "        x_subset = scaler.scale(x_subset)\n",
    "\n",
    "        # Predict the output events.\n",
    "        y_pred = spatial_temporal_gnn(x_subset.unsqueeze(0).to(device))\n",
    "        \n",
    "        y_pred[y.unsqueeze(0) == 0] = 0\n",
    "        y_pred = scaler.un_scale(y_pred)\n",
    "\n",
    "        # Compute the reward as the negative MAE between the predicted\n",
    "        # output events and the actual output events.\n",
    "        reward = - mae_criterion(y_pred, y.unsqueeze(0).to(device)).item()\n",
    "        return reward\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        \"\"\"Hash the node by the input events.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            The hash of the node.\n",
    "        \"\"\"\n",
    "        return hash(frozenset(self.input_events))\n",
    "\n",
    "    def __eq__(node1: 'Node', node2: 'Node') -> bool:\n",
    "        \"\"\"Get whether or not two nodes are equal.\n",
    "        A node is equal to another node if they have the same input\n",
    "        events set.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        node1 : Node\n",
    "            The first node to compare.\n",
    "        node2 : Node\n",
    "            The second node to compare.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bool\n",
    "            Whether or not the two nodes are equal.\n",
    "        \"\"\"\n",
    "        return frozenset(node1.input_events) == frozenset(node2.input_events)\n",
    "        #return node1.input_events == node2.input_events\n",
    "\n",
    "class MonteCarloTreeSearch:\n",
    "    \"Monte Carlo Tree Search. First rollout the tree then choose a move.\"\n",
    "\n",
    "    def __init__(\n",
    "        self, spatial_temporal_gnn: SpatialTemporalGNN, navigator: Navigator,\n",
    "        x: torch.FloatTensor, y: torch.FloatTensor,\n",
    "        maximum_leaf_size: int = 20, exploration_weight: int = 1) -> None:\n",
    "        \"\"\"Initialize the MCTS.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        spatial_temporal_gnn : SpatialTemporalGNN\n",
    "            The Spatial Temporal Graph Neural Network used to get the\n",
    "            reward of a leaf node.\n",
    "        navigator : Navigator\n",
    "            The Navigator used to select which node to expand during\n",
    "            the tree search.\n",
    "        exploration_weight : int, optional\n",
    "            The exploration weight used in the Upper Confidence Bound\n",
    "            for Trees (UCT) formula, by default 1.\n",
    "        \"\"\"\n",
    "        # Set dictionary of total reward of each node.\n",
    "        self.C = defaultdict(int)\n",
    "        # Set dictionary of total visit count for each node.\n",
    "        self.N = defaultdict(int)\n",
    "        # Set dictionary of children of each node.\n",
    "        self.children = dict()\n",
    "        # Set dictionary of expanded children of each node.\n",
    "        self.expanded_children = dict()\n",
    "        # Set the best found leaf node along with its error.\n",
    "        self.best_leaf = ( None, - math.inf )\n",
    "        # Set the exploration weight.\n",
    "        self.exploration_weight = exploration_weight\n",
    "        # Set the Spatial Temporal Graph Neural Network.\n",
    "        self.spatial_temporal_gnn = spatial_temporal_gnn\n",
    "        # Set the Navigator.\n",
    "        self.navigator = navigator\n",
    "        # Set the maximum leaf size.\n",
    "        self.maximum_leaf_size = maximum_leaf_size\n",
    "        # Set the inputs\n",
    "        self.x = x.clone()\n",
    "        # Set the outputs\n",
    "        self.y = y.clone()\n",
    "        # Set the target events.\n",
    "        self.target_events = [[e[1], e[2], y[e[1], e[2], 0]] \n",
    "                              for e in get_largest_event_set(y)]\n",
    "\n",
    "    def rollout(self, node: Node) -> None:\n",
    "        \"\"\"Do a Monte Carlo Tree Search rollout starting from the given\n",
    "        root node and reaching a leaf node. After the rollout, the leaf node\n",
    "        is saved as the best leaf node if it has a lower error than the\n",
    "        current best leaf node. Moreover, the reward is backpropogated\n",
    "        from the leaf node to the root node in order to update the\n",
    "        total reward and total visit count of each node.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        node : Node\n",
    "            The root node of the tree search.\n",
    "        \"\"\"\n",
    "        # Get the path from the root node to the leaf node.\n",
    "        # Apply node expansion through the navigator and node selection\n",
    "        # through the Upper Confidence Bound applied to Trees (UCT).\n",
    "        path = self._select(node)\n",
    "        # Get the leaf node.\n",
    "        leaf = path[-1]\n",
    "        #### self._expand(leaf)\n",
    "        # Get the reward of the leaf node.\n",
    "        reward = self._simulate(leaf)\n",
    "        # Backpropogate the reward from the leaf node to the root node.\n",
    "        self._backpropagate(path, reward)\n",
    "        #print(path)\n",
    "\n",
    "    def _select(self, node: Node):\n",
    "        \"Find an unexplored descendent of `node`\"\n",
    "        # Set the rollout path.\n",
    "        path = []\n",
    "        while True:\n",
    "            # Append the node to the path.\n",
    "            path.append(node)\n",
    "            # If the node is a terminal node, return the path.\n",
    "            if node.is_terminal(self.maximum_leaf_size):\n",
    "                return path\n",
    "            # Expand the node children.\n",
    "            self._expand(node)\n",
    "            # Explore the child node that maximizes the Upper Confidence\n",
    "            # Bound applied to Trees (UCT) formula.\n",
    "            node = self._get_node_by_upper_confidence_bound(node)\n",
    "\n",
    "    def _expand(self, node: Node) -> None:\n",
    "        \"Update the `children` dict with the children of `node`\"\n",
    "        if node not in self.children.keys():\n",
    "            if node not in self.expanded_children.keys():\n",
    "                # The node has never been expanded yet.\n",
    "                self.children[node] = [ e for e in node.input_events ]\n",
    "                #self.children[node] = node.find_children()\n",
    "                self.expanded_children[node] = []\n",
    "            else:\n",
    "                # The node has been fully expanded.\n",
    "                return\n",
    "        # Get the best child of the node according to the correlation score.\n",
    "        #best_child_idx = np.argmax(\n",
    "        #    [n.correlation_score for n in self.children[node]])\n",
    "        # Add the best child to the expanded children of the node.\n",
    "        input_events = [ e for e in node.input_events ]\n",
    "        input_events.remove(self.children[node][0])\n",
    "        self.expanded_children[node].append(Node(input_events))\n",
    "        # Delete the expanded child from the children of the node.\n",
    "        del self.children[node][0]#[best_child_idx]\n",
    "\n",
    "    def _simulate(self, node: Node) -> float:\n",
    "        \"Returns the reward for a random simulation (to completion) of `node`\"\n",
    "        # Assumes node is terminal\n",
    "        # input_events = [[0, e[0], e[1]] for e in node.input_events]\n",
    "        #x = remove_features_by_events(self.x, input_events)\n",
    "\n",
    "        reward = node.reward(self.spatial_temporal_gnn, self.x, self.y)\n",
    "        #print(reward)\n",
    "        if reward > self.best_leaf[1]:\n",
    "            self.best_leaf = (node, reward)\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def _backpropagate(self, path: List[Node], reward: float) -> None:\n",
    "        \"\"\"Backpropagate the reward from the node to its ancestors.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path : list of Node\n",
    "            The path from the root node to the leaf node.\n",
    "        reward : float\n",
    "            The reward score of the leaf node to backpropagate.\n",
    "        \"\"\"\n",
    "        reward /= 100.\n",
    "        for node in reversed(path):\n",
    "            self.N[node] += 1\n",
    "            self.C[node] += reward\n",
    "            reward += 1  # Add 1 to the reward for the parent node.\n",
    "\n",
    "    def _get_node_by_upper_confidence_bound(self, node: Node) -> Node:\n",
    "        \"\"\"\n",
    "        Get a child node of the given node by the Upper Confidence Bound\n",
    "        for Trees (UCT) algorithm, balancing exploration & exploitation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        node : Node\n",
    "            The parent node to get a child of to explore.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Node\n",
    "            The child node to explore.\n",
    "        \"\"\"\n",
    "        #\"Select a child of node, balancing exploration & exploitation\"\n",
    "\n",
    "        # All children of node should already be expanded:\n",
    "        #assert all(n in self.expanded_children \n",
    "        #           for n in self.expanded_children[node])\n",
    "\n",
    "        #log_N_vertex = math.log(self.N[node])\n",
    "        # Get the sum of total visit count of each children.\n",
    "        N_sum = sum([self.N[c] for c in self.expanded_children[node]])\n",
    "\n",
    "        def get_upper_confidence_bound(n: Node) -> float:\n",
    "            \"\"\"\n",
    "            Get the Upper Confidence Bound for Trees (UCT) of a child\n",
    "            Node.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            n : Node\n",
    "                The child node to get the UCT of.\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            float\n",
    "                The UCT of the child node.\n",
    "            \"\"\"\n",
    "            #return self.C[n] / self.N[n] + self.exploration_weight * math.sqrt(\n",
    "            #    log_N_vertex / self.N[n]\n",
    "            #)\n",
    "            return self.C[n] / (self.N[n] + 1e-10) + self.exploration_weight * math.sqrt(N_sum) / (self.N[n] + 1)\n",
    "\n",
    "        return max(self.expanded_children[node], key=get_upper_confidence_bound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample, y_sample = x_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[6.43750000e+01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.76250000e+01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.71250000e+01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [5.92500000e+01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.90000000e+01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.18750000e+01, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[6.26666667e+01, 3.47463516e-03, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.85555556e+01, 3.47463516e-03, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.54444444e+01, 3.47463516e-03, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [5.58888889e+01, 3.47463516e-03, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.84444444e+01, 3.47463516e-03, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.28750000e+01, 3.47463516e-03, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[6.40000000e+01, 6.94927033e-03, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.37500000e+01, 6.94927033e-03, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.00000000e+01, 6.94927033e-03, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [6.13750000e+01, 6.94927033e-03, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.98571429e+01, 6.94927033e-03, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.20000000e+01, 6.94927033e-03, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[6.35000000e+01, 3.12717165e-02, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.15000000e+01, 3.12717165e-02, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.25000000e+01, 3.12717165e-02, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [5.07500000e+01, 3.12717165e-02, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.62500000e+01, 3.12717165e-02, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.22500000e+01, 3.12717165e-02, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[6.52222222e+01, 3.47463516e-02, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.36666667e+01, 3.47463516e-02, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.51111111e+01, 3.47463516e-02, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [6.05555556e+01, 3.47463516e-02, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.72222222e+01, 3.47463516e-02, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.00000000e+01, 3.47463516e-02, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]],\n",
       "\n",
       "       [[6.22500000e+01, 3.82209868e-02, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.77500000e+01, 3.82209868e-02, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.68750000e+01, 3.82209868e-02, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [5.70000000e+01, 3.82209868e-02, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [6.65000000e+01, 3.82209868e-02, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [5.94285714e+01, 3.82209868e-02, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = spatial_temporal_gnn(scaler.scale(torch.Tensor(x_sample).unsqueeze(0).float().to('cuda'))).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = scaler.un_scale(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[63.9978],\n",
       "         [65.0084],\n",
       "         [64.3614],\n",
       "         ...,\n",
       "         [56.0795],\n",
       "         [67.0944],\n",
       "         [61.0340]],\n",
       "\n",
       "        [[64.0564],\n",
       "         [64.8449],\n",
       "         [64.2104],\n",
       "         ...,\n",
       "         [55.2518],\n",
       "         [66.8870],\n",
       "         [60.8755]],\n",
       "\n",
       "        [[64.1436],\n",
       "         [64.9091],\n",
       "         [64.2355],\n",
       "         ...,\n",
       "         [55.0873],\n",
       "         [67.1334],\n",
       "         [60.7365]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[64.8023],\n",
       "         [65.3382],\n",
       "         [64.9307],\n",
       "         ...,\n",
       "         [53.2081],\n",
       "         [67.8508],\n",
       "         [60.2876]],\n",
       "\n",
       "        [[64.9726],\n",
       "         [65.2504],\n",
       "         [64.7857],\n",
       "         ...,\n",
       "         [52.6331],\n",
       "         [68.0798],\n",
       "         [60.1956]],\n",
       "\n",
       "        [[64.1031],\n",
       "         [64.5448],\n",
       "         [63.9792],\n",
       "         ...,\n",
       "         [51.4882],\n",
       "         [67.1194],\n",
       "         [59.5147]]], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[torch.Tensor(y_sample) == 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([69.166954, 68.800095, 69.31903 , 70.10495 , 69.646835, 70.45398 ,\n",
       "       69.90516 , 70.29881 , 70.60335 , 71.06508 , 70.954185, 69.60902 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sample[y_sample != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([69.1670, 68.8001, 69.3190, 70.1049, 69.6468, 70.4540, 69.9052, 70.2988,\n",
       "        70.6033, 71.0651, 70.9542, 69.6090], device='cuda:0',\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[y_pred != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(y_pred.to('cuda').float() == torch.Tensor(y_sample).to('cuda').float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "477\n",
      "Execution 1/50\n",
      "mae: 9.12005615234375\n",
      "Execution 2/50\n",
      "mae: 9.105835914611816\n",
      "Execution 3/50\n",
      "mae: 9.105835914611816\n",
      "Execution 4/50\n",
      "mae: 9.105835914611816\n",
      "Execution 5/50\n",
      "mae: 9.105835914611816\n",
      "Execution 6/50\n",
      "mae: 9.105835914611816\n",
      "Execution 7/50\n",
      "mae: 9.105835914611816\n",
      "Execution 8/50\n",
      "mae: 9.105835914611816\n",
      "Execution 9/50\n",
      "mae: 9.105835914611816\n",
      "Execution 10/50\n",
      "mae: 9.105835914611816\n",
      "Execution 11/50\n",
      "mae: 9.105835914611816\n",
      "Execution 12/50\n",
      "mae: 9.105835914611816\n",
      "Execution 13/50\n",
      "mae: 9.105835914611816\n",
      "Execution 14/50\n",
      "mae: 9.105835914611816\n",
      "Execution 15/50\n",
      "mae: 9.105835914611816\n",
      "Execution 16/50\n",
      "mae: 9.105835914611816\n",
      "Execution 17/50\n",
      "mae: 9.105835914611816\n",
      "Execution 18/50\n",
      "mae: 9.105835914611816\n",
      "Execution 19/50\n",
      "mae: 9.105835914611816\n",
      "Execution 20/50\n",
      "mae: 9.105835914611816\n",
      "Execution 21/50\n",
      "mae: 9.105835914611816\n",
      "Execution 22/50\n",
      "mae: 9.105835914611816\n",
      "Execution 23/50\n",
      "mae: 9.105835914611816\n",
      "Execution 24/50\n",
      "mae: 9.105835914611816\n",
      "Execution 25/50\n",
      "mae: 9.105835914611816\n",
      "Execution 26/50\n",
      "mae: 9.105835914611816\n",
      "Execution 27/50\n",
      "mae: 9.105835914611816\n",
      "Execution 28/50\n",
      "mae: 9.105835914611816\n",
      "Execution 29/50\n",
      "mae: 9.105835914611816\n",
      "Execution 30/50\n",
      "mae: 9.105835914611816\n",
      "Execution 31/50\n",
      "mae: 9.105835914611816\n",
      "Execution 32/50\n",
      "mae: 9.105835914611816\n",
      "Execution 33/50\n",
      "mae: 9.105835914611816\n",
      "Execution 34/50\n",
      "mae: 9.105835914611816\n",
      "Execution 35/50\n",
      "mae: 9.105835914611816\n",
      "Execution 36/50\n",
      "mae: 9.105835914611816\n",
      "Execution 37/50\n",
      "mae: 9.105835914611816\n",
      "Execution 38/50\n",
      "mae: 9.105835914611816\n",
      "Execution 39/50\n",
      "mae: 9.105835914611816\n",
      "Execution 40/50\n",
      "mae: 9.105835914611816\n",
      "Execution 41/50\n",
      "mae: 9.105835914611816\n",
      "Execution 42/50\n",
      "mae: 9.105835914611816\n",
      "Execution 43/50\n",
      "mae: 9.105072021484375\n",
      "Execution 44/50\n",
      "mae: 9.105072021484375\n",
      "Execution 45/50\n",
      "mae: 9.105072021484375\n",
      "Execution 46/50\n",
      "mae: 9.105072021484375\n",
      "Execution 47/50\n",
      "mae: 9.105072021484375\n",
      "Execution 48/50\n",
      "mae: 9.105072021484375\n",
      "Execution 49/50\n",
      "mae: 9.105072021484375\n",
      "Execution 50/50\n",
      "mae: 9.105072021484375\n"
     ]
    }
   ],
   "source": [
    "from src.explanation.events import get_largest_event_set\n",
    "\n",
    "\n",
    "x_sample, y_sample = x_train[0], y_train[0]\n",
    "x_sample = x_sample.copy()\n",
    "\n",
    "target_events = [[e[1], e[2], y_sample[e[1], e[2], 0]] \n",
    "                 for e in get_largest_event_set(y_sample)]\n",
    "\n",
    "'''input_events = get_largest_event_set(x_sample)\n",
    "input_events = [i for i in input_events if i[0] == 0] # TODO: Get all kind of events\n",
    "\n",
    "\n",
    "input_events_with_correlation_score = []\n",
    "for i, e in enumerate(input_events):\n",
    "    encoded_information = x_sample[e[1], e[2], :]\n",
    "    e_ = (e[1], e[2], *encoded_information)\n",
    "    target_batch = torch.FloatTensor(target_events).to(navigator.device)\n",
    "    # Repeat the input event e for each target event to generate a\n",
    "    # batch of input events corresponding to the target events.\n",
    "    e_unsqueezed = np.expand_dims(e_, axis=0)\n",
    "    input_batch = torch.FloatTensor(\n",
    "        np.repeat(e_unsqueezed, len(target_events), axis=0)\n",
    "        ).to(navigator.device)\n",
    "\n",
    "    # Get the correlation score average between the input events and\n",
    "    # the target events.\n",
    "    correlation_score_avg = navigator(\n",
    "        input_batch, target_batch).mean().item()\n",
    "    input_events_with_correlation_score.append(\n",
    "        (e_, correlation_score_avg))\n",
    "\n",
    "for e in sorted(input_events_with_correlation_score, key=lambda x: x[1]):#[-800:]:\n",
    "    x_sample[e[0][0], e[0][1], 0] = 0.'''\n",
    "\n",
    "input_events = get_largest_event_set(x_sample)\n",
    "input_events = [i for i in input_events if i[0] == 0]\n",
    "\n",
    "# TODO: repeated code\n",
    "input_events_with_correlation_score = []\n",
    "for i, e in enumerate(input_events):\n",
    "    encoded_information = x_sample[e[1], e[2], :]\n",
    "    e_ = (e[1], e[2], *encoded_information)\n",
    "    target_batch = torch.FloatTensor(target_events).to(navigator.device)\n",
    "    # Repeat the input event e for each target event to generate a\n",
    "    # batch of input events corresponding to the target events.\n",
    "    e_unsqueezed = np.expand_dims(e_, axis=0)\n",
    "    input_batch = torch.FloatTensor(\n",
    "        np.repeat(e_unsqueezed, len(target_events), axis=0)\n",
    "        ).to(navigator.device)\n",
    "\n",
    "    # Get the correlation score average between the input events and\n",
    "    # the target events.\n",
    "    correlation_score_avg = navigator(\n",
    "        input_batch, target_batch).mean().item()\n",
    "    input_events_with_correlation_score.append(\n",
    "        (e_, correlation_score_avg))\n",
    "# TODO: end repeated code;\n",
    "\n",
    "input_events_with_correlation_score = sorted(\n",
    "    input_events_with_correlation_score, key=lambda x: x[1])[-500:]\n",
    "\n",
    "print(len(input_events_with_correlation_score))\n",
    "\n",
    "T = 12\n",
    "heuristical_steps = np.linspace(.1, .12, T, dtype=np.float32, endpoint=False)[::-1]\n",
    "#print(heuristical_steps)\n",
    "\n",
    "for t, s in enumerate(heuristical_steps):\n",
    "    for i, e in enumerate(input_events_with_correlation_score):\n",
    "        input_timestep = e[0][0]\n",
    "        if input_timestep != t:\n",
    "            continue\n",
    "        is_out_of_reach = True\n",
    "        for target_node in np.unique([ e[1] for e in target_events ]):\n",
    "            input_node = e[0][1]\n",
    "            if adj_matrix[input_node, target_node] <= s or adj_matrix[target_node, input_node] <= s:\n",
    "                is_out_of_reach = False\n",
    "                break\n",
    "        if is_out_of_reach:\n",
    "            del input_events_with_correlation_score[i]\n",
    "\n",
    "print(len(input_events_with_correlation_score))\n",
    "\n",
    "monte_carlo_tree_search = MonteCarloTreeSearch(\n",
    "    spatial_temporal_gnn,\n",
    "    navigator,\n",
    "    torch.FloatTensor(x_sample).to(device=spatial_temporal_gnn.device),\n",
    "    torch.FloatTensor(y_sample).to(device=spatial_temporal_gnn.device),\n",
    "    maximum_leaf_size=50, exploration_weight=500)\n",
    "\n",
    "root = Node(input_events=[e for e, _ in input_events_with_correlation_score])\n",
    "\n",
    "for i in range(50):\n",
    "    print(f'Execution {i+1}/50')\n",
    "    monte_carlo_tree_search.rollout(root)\n",
    "    print('mae:', - monte_carlo_tree_search.best_leaf[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_events_with_correlation_score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  5  6  7  8  9 10 11]\n",
      "[ 0  1  2  3  4  6  7  8  9 10 12 14 18 21 22 35 62]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique([ e[0] for e in monte_carlo_tree_search.best_leaf[0].input_events ]))\n",
    "print(np.unique([ e[1] for e in monte_carlo_tree_search.best_leaf[0].input_events ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(monte_carlo_tree_search.C.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in monte_carlo_tree_search.C.items():\n",
    "#    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(y_sample[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  5  6  7  8  9 10 11]\n",
      "[ 0  1  2  3  4  6  7  8  9 10 12 14 18 21 22 35 62]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique([ e[0] for e in monte_carlo_tree_search.best_leaf[0].input_events ]))\n",
    "print(np.unique([ e[1] for e in monte_carlo_tree_search.best_leaf[0].input_events ]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
